{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import gym\n",
    "from gym import spaces, logger\n",
    "from gym.utils import seeding\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "class CartPoleEnv(gym.Env):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        A pole is attached by an un-actuated joint to a cart, which moves along\n",
    "        a frictionless track. The pendulum starts upright, and the goal is to\n",
    "        prevent it from falling over by increasing and reducing the cart's\n",
    "        velocity.\n",
    "    Source:\n",
    "        This environment corresponds to the version of the cart-pole problem\n",
    "        described by Barto, Sutton, and Anderson\n",
    "    Observation:\n",
    "        Type: Box(4)\n",
    "        Num     Observation               Min                     Max\n",
    "        0       Cart Position             -4.8                    4.8\n",
    "        1       Cart Velocity             -Inf                    Inf\n",
    "        2       Pole Angle                -0.418 rad (-24 deg)    0.418 rad (24 deg)\n",
    "        3       Pole Angular Velocity     -Inf                    Inf\n",
    "    Actions:\n",
    "        Type: Discrete(2)\n",
    "        Num   Action\n",
    "        0     Push cart to the left\n",
    "        1     Push cart to the right\n",
    "        Note: The amount the velocity that is reduced or increased is not\n",
    "        fixed; it depends on the angle the pole is pointing. This is because\n",
    "        the center of gravity of the pole increases the amount of energy needed\n",
    "        to move the cart underneath it\n",
    "    Reward:\n",
    "        Reward is 1 for every step taken, including the termination step\n",
    "    Starting State:\n",
    "        All observations are assigned a uniform random value in [-0.05..0.05]\n",
    "    Episode Termination:\n",
    "        Pole Angle is more than 12 degrees.\n",
    "        Cart Position is more than 2.4 (center of the cart reaches the edge of\n",
    "        the display).\n",
    "        Episode length is greater than 200.\n",
    "        Solved Requirements:\n",
    "        Considered solved when the average return is greater than or equal to\n",
    "        195.0 over 100 consecutive trials.\n",
    "    \"\"\"\n",
    "\n",
    "    #metadata = {\"render.modes\": [\"human\", \"rgb_array\"], \"video.frames_per_second\": 50}\n",
    "\n",
    "    def __init__(self):\n",
    "        self.gravity = 9.8\n",
    "        self.masscart = 1.0\n",
    "        self.masspole = 0.1\n",
    "        self.total_mass = self.masspole + self.masscart\n",
    "        self.length = 0.5  # actually half the pole's length\n",
    "        self.polemass_length = self.masspole * self.length\n",
    "        self.force_mag = 10.0\n",
    "        self.tau = 0.02  # seconds between state updates\n",
    "        self.kinematics_integrator = \"euler\"\n",
    "\n",
    "        # Angle at which to fail the episode\n",
    "        #self.theta_threshold_radians = 12 * 2 * math.pi / 360\n",
    "        #self.x_threshold = 2.4\n",
    "\n",
    "        # Angle limit set to 2 * theta_threshold_radians so failing observation\n",
    "        # is still within bounds.\n",
    "        high = np.array(\n",
    "            [\n",
    "                160,\n",
    "                10,\n",
    "                 10,\n",
    "                10,\n",
    "            ],\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "\n",
    "        self.action_space = spaces.Discrete(2)\n",
    "        self.observation_space = spaces.Box(-high, high, dtype=np.float32)\n",
    "\n",
    "        self.seed()\n",
    "        self.viewer = None\n",
    "        self.state = None\n",
    "\n",
    "        self.steps_beyond_done = None\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def step(self, action):\n",
    "        err_msg = \"%r (%s) invalid\" % (action, type(action))\n",
    "        assert self.action_space.contains(action), err_msg\n",
    "        \n",
    "        \n",
    "        \n",
    "        # For the interested reader:\n",
    "        # https://coneural.org/florian/papers/05_cart_pole.pdf\n",
    "        \n",
    "\n",
    "        r=random.choices(t)\n",
    "        r[0][0], r[0][1], r[0][2], r[0][2] = self.state\n",
    "        r[0][1]=r[0][1]+1\n",
    "        self.state = (r[0][0], r[0][1], r[0][2], r[0][2])\n",
    "\n",
    "        done=bool(r[0][0]==1)\n",
    "\n",
    "        if not done:\n",
    "            reward = 1.0\n",
    "        elif self.steps_beyond_done is None:\n",
    "            # Pole just fell!\n",
    "            self.steps_beyond_done = 0\n",
    "            reward = 1.0\n",
    "        \n",
    "        return np.array(self.state, dtype=np.float32), reward, done, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = self.np_random.uniform(low=-0.05, high=0.05, size=(4,))\n",
    "        self.steps_beyond_done = None\n",
    "        return np.array(self.state, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Classic cart-pole system implemented by Rich Sutton et al.\n",
    "Copied from http://incompleteideas.net/sutton/book/code/pole.c\n",
    "permalink: https://perma.cc/C9ZM-652R\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "import gym\n",
    "from gym import spaces, logger\n",
    "from gym.utils import seeding\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "class CartPoleEnv1(gym.Env):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        A pole is attached by an un-actuated joint to a cart, which moves along\n",
    "        a frictionless track. The pendulum starts upright, and the goal is to\n",
    "        prevent it from falling over by increasing and reducing the cart's\n",
    "        velocity.\n",
    "    Source:\n",
    "        This environment corresponds to the version of the cart-pole problem\n",
    "        described by Barto, Sutton, and Anderson\n",
    "    Observation:\n",
    "        Type: Box(4)\n",
    "        Num     Observation               Min                     Max\n",
    "        0       Cart Position             -4.8                    4.8\n",
    "        1       Cart Velocity             -Inf                    Inf\n",
    "        2       Pole Angle                -0.418 rad (-24 deg)    0.418 rad (24 deg)\n",
    "        3       Pole Angular Velocity     -Inf                    Inf\n",
    "    Actions:\n",
    "        Type: Discrete(2)\n",
    "        Num   Action\n",
    "        0     Push cart to the left\n",
    "        1     Push cart to the right\n",
    "        Note: The amount the velocity that is reduced or increased is not\n",
    "        fixed; it depends on the angle the pole is pointing. This is because\n",
    "        the center of gravity of the pole increases the amount of energy needed\n",
    "        to move the cart underneath it\n",
    "    Reward:\n",
    "        Reward is 1 for every step taken, including the termination step\n",
    "    Starting State:\n",
    "        All observations are assigned a uniform random value in [-0.05..0.05]\n",
    "    Episode Termination:\n",
    "        Pole Angle is more than 12 degrees.\n",
    "        Cart Position is more than 2.4 (center of the cart reaches the edge of\n",
    "        the display).\n",
    "        Episode length is greater than 200.\n",
    "        Solved Requirements:\n",
    "        Considered solved when the average return is greater than or equal to\n",
    "        195.0 over 100 consecutive trials.\n",
    "    \"\"\"\n",
    "\n",
    "    #metadata = {\"render.modes\": [\"human\", \"rgb_array\"], \"video.frames_per_second\": 50}\n",
    "\n",
    "    def __init__(self):\n",
    "        self.gravity = 9.8\n",
    "        self.masscart = 1.0\n",
    "        self.masspole = 0.1\n",
    "        self.total_mass = self.masspole + self.masscart\n",
    "        self.length = 0.5  # actually half the pole's length\n",
    "        self.polemass_length = self.masspole * self.length\n",
    "        self.force_mag = 10.0\n",
    "        self.tau = 0.02  # seconds between state updates\n",
    "        self.kinematics_integrator = \"euler\"\n",
    "\n",
    "        # Angle at which to fail the episode\n",
    "        self.theta_threshold_radians = 12 * 2 * math.pi / 360\n",
    "        self.x_threshold = 2.4\n",
    "\n",
    "        # Angle limit set to 2 * theta_threshold_radians so failing observation\n",
    "        # is still within bounds.\n",
    "        high = np.array(\n",
    "            [\n",
    "                1,\n",
    "                100,\n",
    "                100,\n",
    "                100,\n",
    "            ],\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "\n",
    "        self.action_space = spaces.Discrete(2)\n",
    "        self.observation_space = spaces.Box(-high, high, dtype=np.float32)\n",
    "\n",
    "        self.seed()\n",
    "        self.viewer = None\n",
    "        self.state = None\n",
    "\n",
    "        self.steps_beyond_done = None\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def step(self, action):\n",
    "        err_msg = \"%r (%s) invalid\" % (action, type(action))\n",
    "        assert self.action_space.contains(action), err_msg\n",
    "\n",
    "        x, x_dot, theta, theta_dot = self.state\n",
    "        i=1\n",
    "         \n",
    "        # For the interested reader:\n",
    "        # https://coneural.org/florian/papers/05_cart_pole.pdf\n",
    "        \n",
    "        #t=[1,5,4]\n",
    "        reward=0\n",
    "        a=5\n",
    "        b=5\n",
    "        \n",
    "        \n",
    "        #for i in range(20):\n",
    "        \n",
    "        if random.random()>math.exp(-a/b):\n",
    "            x=0\n",
    "            x_dot = 3\n",
    "            theta = 3\n",
    "            theta_dot = 4\n",
    "            reward = -1\n",
    "            b+=1\n",
    "            a-=1\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        else:\n",
    "            x = 1\n",
    "            x_dot =x_dot+i\n",
    "            theta = 3\n",
    "            theta_dot = 4\n",
    "            \n",
    "            \n",
    "            \n",
    "            i+=1\n",
    "            reward = 1\n",
    "        #if self.kinematics_integrator == \"euler\":\n",
    "        #x = t[0][0]\n",
    "        \n",
    "          \n",
    "        self.state = (x, x_dot, theta, theta_dot)\n",
    "\n",
    "        done = bool(x_dot>40)\n",
    "        \n",
    "        a=a\n",
    "        b=b\n",
    "       \n",
    "        \n",
    "\n",
    "        return np.array(self.state, dtype=np.float32), reward, done, {}\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        \n",
    "        #self.state = self.np_random.randint(low=0, high=1, size=(4,))\n",
    "        #self.state = (1,2,3,3),(1,2,3,3)\n",
    "      \n",
    "       self.state = self.np_random.uniform(low=-0.05, high=0.05, size=(4,))\n",
    "       self.steps_beyond_done = None\n",
    "       return np.array(self.state, dtype=np.float32)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Classic cart-pole system implemented by Rich Sutton et al.\n",
    "Copied from http://incompleteideas.net/sutton/book/code/pole.c\n",
    "permalink: https://perma.cc/C9ZM-652R\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "import gym\n",
    "from gym import spaces, logger\n",
    "from gym.utils import seeding\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "\n",
    "class CartPoleEnv3(gym.Env):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        A pole is attached by an un-actuated joint to a cart, which moves along\n",
    "        a frictionless track. The pendulum starts upright, and the goal is to\n",
    "        prevent it from falling over by increasing and reducing the cart's\n",
    "        velocity.\n",
    "    Source:\n",
    "        This environment corresponds to the version of the cart-pole problem\n",
    "        described by Barto, Sutton, and Anderson\n",
    "    Observation:\n",
    "        Type: Box(4)\n",
    "        Num     Observation               Min                     Max\n",
    "        0       Cart Position             -4.8                    4.8\n",
    "        1       Cart Velocity             -Inf                    Inf\n",
    "        2       Pole Angle                -0.418 rad (-24 deg)    0.418 rad (24 deg)\n",
    "        3       Pole Angular Velocity     -Inf                    Inf\n",
    "    Actions:\n",
    "        Type: Discrete(2)\n",
    "        Num   Action\n",
    "        0     Push cart to the left\n",
    "        1     Push cart to the right\n",
    "        Note: The amount the velocity that is reduced or increased is not\n",
    "        fixed; it depends on the angle the pole is pointing. This is because\n",
    "        the center of gravity of the pole increases the amount of energy needed\n",
    "        to move the cart underneath it\n",
    "    Reward:\n",
    "        Reward is 1 for every step taken, including the termination step\n",
    "    Starting State:\n",
    "        All observations are assigned a uniform random value in [-0.05..0.05]\n",
    "    Episode Termination:\n",
    "        Pole Angle is more than 12 degrees.\n",
    "        Cart Position is more than 2.4 (center of the cart reaches the edge of\n",
    "        the display).\n",
    "        Episode length is greater than 200.\n",
    "        Solved Requirements:\n",
    "        Considered solved when the average return is greater than or equal to\n",
    "        195.0 over 100 consecutive trials.\n",
    "    \"\"\"\n",
    "\n",
    "    #metadata = {\"render.modes\": [\"human\", \"rgb_array\"], \"video.frames_per_second\": 50}\n",
    "\n",
    "    def __init__(self):\n",
    "        self.gravity = 9.8\n",
    "        self.masscart = 1.0\n",
    "        self.masspole = 0.1\n",
    "        self.total_mass = self.masspole + self.masscart\n",
    "        self.length = 0.5  # actually half the pole's length\n",
    "        self.polemass_length = self.masspole * self.length\n",
    "        self.force_mag = 1.0\n",
    "        self.tau = 0.02  # seconds between state updates\n",
    "        self.kinematics_integrator = \"euler\"\n",
    "\n",
    "        # Angle at which to fail the episode\n",
    "        self.theta_threshold_radians = 12 * 2 * math.pi / 360\n",
    "        self.x_threshold = 2.4\n",
    "\n",
    "        # Angle limit set to 2 * theta_threshold_radians so failing observation\n",
    "        # is still within bounds.\n",
    "        high = np.array(\n",
    "            [\n",
    "                1,\n",
    "                100,\n",
    "                100,\n",
    "                100,\n",
    "            ],\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "\n",
    "        self.action_space = spaces.Discrete(2)\n",
    "        self.observation_space = spaces.Box(-high, high, dtype=np.float32)\n",
    "\n",
    "        self.seed()\n",
    "        self.viewer = None\n",
    "        self.state = None\n",
    "\n",
    "        self.steps_beyond_done = None\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def step(self, action):\n",
    "        err_msg = \"%r (%s) invalid\" % (action, type(action))\n",
    "        assert self.action_space.contains(action), err_msg\n",
    "\n",
    "        x, x_dot, theta, theta_dot = self.state\n",
    "        force = self.force_mag if action == 1 else -self.force_mag\n",
    "        d=1\n",
    "         \n",
    "        # For the interested reader:\n",
    "        # https://coneural.org/florian/papers/05_cart_pole.pdf\n",
    "        \n",
    "        #t=[1,5,4]\n",
    "        reward=0\n",
    "        a=35\n",
    "        b=50\n",
    "        k=0\n",
    "        \n",
    "        #for i in range(20):\n",
    "        \n",
    "        \n",
    "        if random.random()<math.exp(-a/b)*.63:\n",
    "            x = 1\n",
    "            d+=1*force\n",
    "            x_dot =x_dot+d\n",
    "            theta = 3\n",
    "            theta_dot = 4\n",
    "            k+=1\n",
    "            d+=1*force\n",
    "            \n",
    "            \n",
    "            \n",
    "            reward = 1+d\n",
    "            \n",
    "            \n",
    "           \n",
    "            \n",
    "        else:\n",
    "            \n",
    "            x=0\n",
    "            x_dot = x_dot+d\n",
    "            theta = 3\n",
    "            theta_dot = 4\n",
    "            reward = -(1+d)\n",
    "            \n",
    "            \n",
    "            b+=1\n",
    "            a-=1\n",
    "        #if self.kinematics_integrator == \"euler\":\n",
    "        #x = t[0][0]\n",
    "        \n",
    "          \n",
    "        self.state = (x, x_dot, theta, theta_dot)\n",
    "\n",
    "        done = bool(x_dot>100)\n",
    "        \n",
    "        a=a\n",
    "        b=b\n",
    "       \n",
    "        \n",
    "\n",
    "        return np.array(self.state, dtype=np.float32), reward, done, {}\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        \n",
    "        #self.state = self.np_random.randint(low=0, high=1, size=(4,))\n",
    "       self.state = (1),(1),(1),(1)\n",
    "      \n",
    "       #self.state = self.np_random.uniform(low=0, high=0, size=(4,))\n",
    "       #self.state=self.np.random.uniform(size = (4,), low = 0, high = 1)\n",
    "       self.steps_beyond_done = None\n",
    "       return np.array(self.state, dtype=np.float32)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Classic cart-pole system implemented by Rich Sutton et al.\n",
    "Copied from http://incompleteideas.net/sutton/book/code/pole.c\n",
    "permalink: https://perma.cc/C9ZM-652R\n",
    "\"\"\"\n",
    "\n",
    "import math\n",
    "import gym\n",
    "from gym import spaces, logger\n",
    "from gym.utils import seeding\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class CartPoleEnv2(gym.Env):\n",
    "    \"\"\"\n",
    "    Description:\n",
    "        A pole is attached by an un-actuated joint to a cart, which moves along\n",
    "        a frictionless track. The pendulum starts upright, and the goal is to\n",
    "        prevent it from falling over by increasing and reducing the cart's\n",
    "        velocity.\n",
    "    Source:\n",
    "        This environment corresponds to the version of the cart-pole problem\n",
    "        described by Barto, Sutton, and Anderson\n",
    "    Observation:\n",
    "        Type: Box(4)\n",
    "        Num     Observation               Min                     Max\n",
    "        0       Cart Position             -4.8                    4.8\n",
    "        1       Cart Velocity             -Inf                    Inf\n",
    "        2       Pole Angle                -0.418 rad (-24 deg)    0.418 rad (24 deg)\n",
    "        3       Pole Angular Velocity     -Inf                    Inf\n",
    "    Actions:\n",
    "        Type: Discrete(2)\n",
    "        Num   Action\n",
    "        0     Push cart to the left\n",
    "        1     Push cart to the right\n",
    "        Note: The amount the velocity that is reduced or increased is not\n",
    "        fixed; it depends on the angle the pole is pointing. This is because\n",
    "        the center of gravity of the pole increases the amount of energy needed\n",
    "        to move the cart underneath it\n",
    "    Reward:\n",
    "        Reward is 1 for every step taken, including the termination step\n",
    "    Starting State:\n",
    "        All observations are assigned a uniform random value in [-0.05..0.05]\n",
    "    Episode Termination:\n",
    "        Pole Angle is more than 12 degrees.\n",
    "        Cart Position is more than 2.4 (center of the cart reaches the edge of\n",
    "        the display).\n",
    "        Episode length is greater than 200.\n",
    "        Solved Requirements:\n",
    "        Considered solved when the average return is greater than or equal to\n",
    "        195.0 over 100 consecutive trials.\n",
    "    \"\"\"\n",
    "\n",
    "    #metadata = {\"render.modes\": [\"human\", \"rgb_array\"], \"video.frames_per_second\": 50}\n",
    "\n",
    "    def __init__(self):\n",
    "        self.gravity = 9.8\n",
    "        self.masscart = 1.0\n",
    "        self.masspole = 0.1\n",
    "        self.total_mass = self.masspole + self.masscart\n",
    "        self.length = 0.5  # actually half the pole's length\n",
    "        self.polemass_length = self.masspole * self.length\n",
    "        self.force_mag = 10.0\n",
    "        self.tau = 0.02  # seconds between state updates\n",
    "        self.kinematics_integrator = \"euler\"\n",
    "\n",
    "        # Angle at which to fail the episode\n",
    "        self.theta_threshold_radians = 12 * 2 * math.pi / 360\n",
    "        self.x_threshold = 2.4\n",
    "\n",
    "        # Angle limit set to 2 * theta_threshold_radians so failing observation\n",
    "        # is still within bounds.\n",
    "        high = np.array(\n",
    "            [\n",
    "                self.x_threshold * 2,\n",
    "                np.finfo(np.float32).max,\n",
    "                self.theta_threshold_radians * 2,\n",
    "                np.finfo(np.float32).max,\n",
    "            ],\n",
    "            dtype=np.float32,\n",
    "        )\n",
    "\n",
    "        self.action_space = spaces.Discrete(2)\n",
    "        self.observation_space = spaces.Box(-high, high, dtype=np.float32)\n",
    "\n",
    "        self.seed()\n",
    "        self.viewer = None\n",
    "        self.state = None\n",
    "\n",
    "        self.steps_beyond_done = None\n",
    "\n",
    "    def seed(self, seed=None):\n",
    "        self.np_random, seed = seeding.np_random(seed)\n",
    "        return [seed]\n",
    "\n",
    "    def step(self, action):\n",
    "        #err_msg = \"%r (%s) invalid\" % (action, type(action))\n",
    "        #assert self.action_space.contains(action), err_msg\n",
    "\n",
    "        x, x_dot, theta, theta_dot = self.state\n",
    "        force = self.force_mag if action == 1 else -self.force_mag\n",
    "        costheta = math.cos(theta)\n",
    "        sintheta = math.sin(theta)\n",
    "\n",
    "        # For the interested reader:\n",
    "        # https://coneural.org/florian/papers/05_cart_pole.pdf\n",
    "        temp = (\n",
    "            force + self.polemass_length * theta_dot ** 2 * sintheta\n",
    "        ) / self.total_mass\n",
    "        thetaacc = (self.gravity * sintheta - costheta * temp) / (\n",
    "            self.length * (4.0 / 3.0 - self.masspole * costheta ** 2 / self.total_mass)\n",
    "        )\n",
    "        xacc = temp - self.polemass_length * thetaacc * costheta / self.total_mass\n",
    "\n",
    "        if self.kinematics_integrator == \"euler\":\n",
    "            x = x + self.tau * x_dot\n",
    "            x_dot = x_dot + self.tau * xacc\n",
    "            theta = theta + self.tau * theta_dot\n",
    "            theta_dot = theta_dot + self.tau * thetaacc\n",
    "        else:  # semi-implicit euler\n",
    "            x_dot = x_dot + self.tau * xacc\n",
    "            x = x + self.tau * x_dot\n",
    "            theta_dot = theta_dot + self.tau * thetaacc\n",
    "            theta = theta + self.tau * theta_dot\n",
    "\n",
    "        self.state = (x, x_dot, theta, theta_dot)\n",
    "\n",
    "        done = bool(\n",
    "            x < -self.x_threshold\n",
    "            or x > self.x_threshold\n",
    "            or theta < -self.theta_threshold_radians\n",
    "            or theta > self.theta_threshold_radians\n",
    "        )\n",
    "\n",
    "        if not done:\n",
    "            reward = 1.0\n",
    "        elif self.steps_beyond_done is None:\n",
    "            # Pole just fell!\n",
    "            self.steps_beyond_done = 0\n",
    "            reward = 1.0\n",
    "        else:\n",
    "            if self.steps_beyond_done == 0:\n",
    "                logger.warn(\n",
    "                    \"You are calling 'step()' even though this \"\n",
    "                    \"environment has already returned done = True. You \"\n",
    "                    \"should always call 'reset()' once you receive 'done = \"\n",
    "                    \"True' -- any further steps are undefined behavior.\"\n",
    "                )\n",
    "            self.steps_beyond_done += 1\n",
    "            reward = 0.0\n",
    "\n",
    "        return np.array(self.state, dtype=np.float32), reward, done, {}\n",
    "\n",
    "    def reset(self):\n",
    "        self.state = self.np_random.uniform(low=0.0, high=0.05, size=(4,))\n",
    "        self.steps_beyond_done = None\n",
    "        return np.array(self.state, dtype=np.float32)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as T\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "class DeepQNetwork(nn.Module):\n",
    "    def __init__(self, lr, input_dims, fc1_dims, fc2_dims,\n",
    "                 n_actions):\n",
    "        super(DeepQNetwork, self).__init__()\n",
    "        self.input_dims = input_dims\n",
    "        self.fc1_dims = fc1_dims\n",
    "        self.fc2_dims = fc2_dims\n",
    "        self.n_actions = n_actions\n",
    "        self.fc1 = nn.Linear(*self.input_dims, self.fc1_dims)\n",
    "        self.fc2 = nn.Linear(self.fc1_dims, self.fc2_dims)\n",
    "        self.fc3 = nn.Linear(self.fc2_dims, self.n_actions)\n",
    "\n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=lr)\n",
    "        self.loss = nn.MSELoss()\n",
    "        self.device = T.device('cuda:0' if T.cuda.is_available() else 'cpu')\n",
    "        self.to(self.device)\n",
    "\n",
    "    def forward(self, state):\n",
    "        x = F.relu(self.fc1(state))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        actions = self.fc3(x)\n",
    "\n",
    "        return actions\n",
    "\n",
    "\n",
    "class Agent:\n",
    "    def __init__(self, gamma, epsilon, lr, input_dims, batch_size, n_actions,\n",
    "                 max_mem_size=100000, eps_end=0.05, eps_dec=5e-4):\n",
    "        self.gamma = gamma\n",
    "        self.epsilon = epsilon\n",
    "        self.eps_min = eps_end\n",
    "        self.eps_dec = eps_dec\n",
    "        self.lr = lr\n",
    "        self.action_space = [i for i in range(n_actions)]\n",
    "        self.mem_size = max_mem_size\n",
    "        self.batch_size = batch_size\n",
    "        self.mem_cntr = 0\n",
    "        self.iter_cntr = 0\n",
    "        self.replace_target = 100\n",
    "\n",
    "        self.Q_eval = DeepQNetwork(lr, n_actions=n_actions,\n",
    "                                   input_dims=input_dims,\n",
    "                                   fc1_dims=256, fc2_dims=256)\n",
    "        self.state_memory = np.zeros((self.mem_size, *input_dims),\n",
    "                                     dtype=np.float32)\n",
    "        self.new_state_memory = np.zeros((self.mem_size, *input_dims),\n",
    "                                         dtype=np.float32)\n",
    "        self.action_memory = np.zeros(self.mem_size, dtype=np.int32)\n",
    "        self.reward_memory = np.zeros(self.mem_size, dtype=np.float32)\n",
    "        self.terminal_memory = np.zeros(self.mem_size, dtype=np.bool)\n",
    "\n",
    "    def store_transition(self, state, action, reward, state_, terminal):\n",
    "        index = self.mem_cntr % self.mem_size\n",
    "        self.state_memory[index] = state\n",
    "        self.new_state_memory[index] = state_\n",
    "        self.reward_memory[index] = reward\n",
    "        self.action_memory[index] = action\n",
    "        self.terminal_memory[index] = terminal\n",
    "\n",
    "        self.mem_cntr += 1\n",
    "\n",
    "    def choose_action(self, observation):\n",
    "        if np.random.random() > self.epsilon:\n",
    "            state = T.tensor([observation]).to(self.Q_eval.device)\n",
    "            actions = self.Q_eval.forward(state)\n",
    "            action = T.argmax(actions).item()\n",
    "        else:\n",
    "            action = np.random.choice(self.action_space)\n",
    "\n",
    "        return action\n",
    "\n",
    "    def learn(self):\n",
    "        if self.mem_cntr < self.batch_size:\n",
    "            return\n",
    "\n",
    "        self.Q_eval.optimizer.zero_grad()\n",
    "\n",
    "        max_mem = min(self.mem_cntr, self.mem_size)\n",
    "\n",
    "        batch = np.random.choice(max_mem, self.batch_size, replace=False)\n",
    "        batch_index = np.arange(self.batch_size, dtype=np.int32)\n",
    "\n",
    "        state_batch = T.tensor(self.state_memory[batch]).to(self.Q_eval.device)\n",
    "        new_state_batch = T.tensor(\n",
    "                self.new_state_memory[batch]).to(self.Q_eval.device)\n",
    "        action_batch = self.action_memory[batch]\n",
    "        reward_batch = T.tensor(\n",
    "                self.reward_memory[batch]).to(self.Q_eval.device)\n",
    "        terminal_batch = T.tensor(\n",
    "                self.terminal_memory[batch]).to(self.Q_eval.device)\n",
    "\n",
    "        q_eval = self.Q_eval.forward(state_batch)[batch_index, action_batch]\n",
    "        q_next = self.Q_eval.forward(new_state_batch)\n",
    "        q_next[terminal_batch] = 0.0\n",
    "\n",
    "        q_target = reward_batch + self.gamma*T.max(q_next, dim=1)[0]\n",
    "\n",
    "        loss = self.Q_eval.loss(q_target, q_eval).to(self.Q_eval.device)\n",
    "        loss.backward()\n",
    "        self.Q_eval.optimizer.step()\n",
    "\n",
    "        self.iter_cntr += 1\n",
    "        self.epsilon = self.epsilon - self.eps_dec \\\n",
    "            if self.epsilon > self.eps_min else self.eps_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import gym\n",
    "\n",
    "def plotLearning(x, scores, epsilons,lines=None):\n",
    "    fig=plt.figure()\n",
    "    ax=fig.add_subplot(111, label=\"1\")\n",
    "    ax2=fig.add_subplot(111, label=\"2\", frame_on=False)\n",
    "\n",
    "    ax.plot(x, epsilons, color=\"C0\")\n",
    "    ax.set_xlabel(\"Game\", color=\"C0\")\n",
    "    ax.set_ylabel(\"Epsilon\", color=\"C0\")\n",
    "    ax.tick_params(axis='x', colors=\"C0\")\n",
    "    ax.tick_params(axis='y', colors=\"C0\")\n",
    "\n",
    "    N = len(scores)\n",
    "    running_avg = np.empty(N)\n",
    "    for t in range(N):\n",
    "\t    running_avg[t] = np.mean(scores[max(0, t-20):(t+1)])\n",
    "\n",
    "    ax2.scatter(x, running_avg, color=\"C1\")\n",
    "    #ax2.xaxis.tick_top()\n",
    "    ax2.axes.get_xaxis().set_visible(False)\n",
    "    ax2.yaxis.tick_right()\n",
    "    #ax2.set_xlabel('x label 2', color=\"C1\")\n",
    "    ax2.set_ylabel('Score', color=\"C1\")\n",
    "    #ax2.xaxis.set_label_position('top')\n",
    "    ax2.yaxis.set_label_position('right')\n",
    "    #ax2.tick_params(axis='x', colors=\"C1\")\n",
    "    ax2.tick_params(axis='y', colors=\"C1\")\n",
    "\n",
    "    if lines is not None:\n",
    "        for line in lines:\n",
    "            plt.axvline(x=line)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode  0 score -66.00 average score -66.00 epsilon 0.98\n",
      "episode  1 score -120.00 average score -93.00 epsilon 0.93\n",
      "episode  2 score -80.00 average score -88.67 epsilon 0.88\n",
      "episode  3 score -24.00 average score -72.50 epsilon 0.83\n",
      "episode  4 score -80.00 average score -74.00 epsilon 0.78\n",
      "episode  5 score -80.00 average score -75.00 epsilon 0.74\n",
      "episode  6 score -56.00 average score -72.29 epsilon 0.69\n",
      "episode  7 score -32.00 average score -67.25 epsilon 0.65\n",
      "episode  8 score -56.00 average score -66.00 epsilon 0.60\n",
      "episode  9 score -48.00 average score -64.20 epsilon 0.55\n",
      "episode  10 score -48.00 average score -62.73 epsilon 0.51\n",
      "episode  11 score -24.00 average score -59.50 epsilon 0.46\n",
      "episode  12 score -24.00 average score -56.77 epsilon 0.42\n",
      "episode  13 score -56.00 average score -56.71 epsilon 0.38\n",
      "episode  14 score -48.00 average score -56.13 epsilon 0.34\n",
      "episode  15 score -80.00 average score -57.62 epsilon 0.29\n",
      "episode  16 score -16.00 average score -55.18 epsilon 0.25\n",
      "episode  17 score -88.00 average score -57.00 epsilon 0.20\n",
      "episode  18 score -56.00 average score -56.95 epsilon 0.16\n",
      "episode  19 score -48.00 average score -56.50 epsilon 0.12\n",
      "episode  20 score 8.00 average score -53.43 epsilon 0.08\n",
      "episode  21 score 22.00 average score -50.00 epsilon 0.04\n",
      "episode  22 score -26.00 average score -48.96 epsilon 0.01\n",
      "episode  23 score -2.00 average score -47.00 epsilon 0.01\n",
      "episode  24 score -16.00 average score -45.76 epsilon 0.01\n",
      "episode  25 score -16.00 average score -44.62 epsilon 0.01\n",
      "episode  26 score -32.00 average score -44.15 epsilon 0.01\n",
      "episode  27 score 16.00 average score -42.00 epsilon 0.01\n",
      "episode  28 score 22.00 average score -39.79 epsilon 0.01\n",
      "episode  29 score 0.00 average score -38.47 epsilon 0.01\n",
      "episode  30 score -16.00 average score -37.74 epsilon 0.01\n",
      "episode  31 score 8.00 average score -36.31 epsilon 0.01\n",
      "episode  32 score 8.00 average score -34.97 epsilon 0.01\n",
      "episode  33 score 16.00 average score -33.47 epsilon 0.01\n",
      "episode  34 score -18.00 average score -33.03 epsilon 0.01\n",
      "episode  35 score -8.00 average score -32.33 epsilon 0.01\n",
      "episode  36 score 32.00 average score -30.59 epsilon 0.01\n",
      "episode  37 score -34.00 average score -30.68 epsilon 0.01\n",
      "episode  38 score -18.00 average score -30.36 epsilon 0.01\n",
      "episode  39 score -48.00 average score -30.80 epsilon 0.01\n",
      "episode  40 score -18.00 average score -30.49 epsilon 0.01\n",
      "episode  41 score 14.00 average score -29.43 epsilon 0.01\n",
      "episode  42 score -56.00 average score -30.05 epsilon 0.01\n",
      "episode  43 score -16.00 average score -29.73 epsilon 0.01\n",
      "episode  44 score 16.00 average score -28.71 epsilon 0.01\n",
      "episode  45 score 30.00 average score -27.43 epsilon 0.01\n",
      "episode  46 score -48.00 average score -27.87 epsilon 0.01\n",
      "episode  47 score -42.00 average score -28.17 epsilon 0.01\n",
      "episode  48 score -2.00 average score -27.63 epsilon 0.01\n",
      "episode  49 score -56.00 average score -28.20 epsilon 0.01\n",
      "episode  50 score 0.00 average score -27.65 epsilon 0.01\n",
      "episode  51 score 38.00 average score -26.38 epsilon 0.01\n",
      "episode  52 score 16.00 average score -25.58 epsilon 0.01\n",
      "episode  53 score 8.00 average score -24.96 epsilon 0.01\n",
      "episode  54 score -16.00 average score -24.80 epsilon 0.01\n",
      "episode  55 score -16.00 average score -24.64 epsilon 0.01\n",
      "episode  56 score -8.00 average score -24.35 epsilon 0.01\n",
      "episode  57 score 32.00 average score -23.38 epsilon 0.01\n",
      "episode  58 score 0.00 average score -22.98 epsilon 0.01\n",
      "episode  59 score 16.00 average score -22.33 epsilon 0.01\n",
      "episode  60 score -16.00 average score -22.23 epsilon 0.01\n",
      "episode  61 score -42.00 average score -22.55 epsilon 0.01\n",
      "episode  62 score -24.00 average score -22.57 epsilon 0.01\n",
      "episode  63 score 8.00 average score -22.09 epsilon 0.01\n",
      "episode  64 score -16.00 average score -22.00 epsilon 0.01\n",
      "episode  65 score -8.00 average score -21.79 epsilon 0.01\n",
      "episode  66 score -8.00 average score -21.58 epsilon 0.01\n",
      "episode  67 score -18.00 average score -21.53 epsilon 0.01\n",
      "episode  68 score -56.00 average score -22.03 epsilon 0.01\n",
      "episode  69 score -40.00 average score -22.29 epsilon 0.01\n",
      "episode  70 score -8.00 average score -22.08 epsilon 0.01\n",
      "episode  71 score -18.00 average score -22.03 epsilon 0.01\n",
      "episode  72 score 0.00 average score -21.73 epsilon 0.01\n",
      "episode  73 score 0.00 average score -21.43 epsilon 0.01\n",
      "episode  74 score -8.00 average score -21.25 epsilon 0.01\n",
      "episode  75 score -72.00 average score -21.92 epsilon 0.01\n",
      "episode  76 score 0.00 average score -21.64 epsilon 0.01\n",
      "episode  77 score -18.00 average score -21.59 epsilon 0.01\n",
      "episode  78 score -16.00 average score -21.52 epsilon 0.01\n",
      "episode  79 score -34.00 average score -21.68 epsilon 0.01\n",
      "episode  80 score -16.00 average score -21.60 epsilon 0.01\n",
      "episode  81 score -40.00 average score -21.83 epsilon 0.01\n",
      "episode  82 score -32.00 average score -21.95 epsilon 0.01\n",
      "episode  83 score 24.00 average score -21.40 epsilon 0.01\n",
      "episode  84 score 8.00 average score -21.06 epsilon 0.01\n",
      "episode  85 score 16.00 average score -20.63 epsilon 0.01\n",
      "episode  86 score -32.00 average score -20.76 epsilon 0.01\n",
      "episode  87 score 0.00 average score -20.52 epsilon 0.01\n",
      "episode  88 score -32.00 average score -20.65 epsilon 0.01\n",
      "episode  89 score -48.00 average score -20.96 epsilon 0.01\n",
      "episode  90 score -40.00 average score -21.16 epsilon 0.01\n",
      "episode  91 score -26.00 average score -21.22 epsilon 0.01\n",
      "episode  92 score -16.00 average score -21.16 epsilon 0.01\n",
      "episode  93 score -8.00 average score -21.02 epsilon 0.01\n",
      "episode  94 score -24.00 average score -21.05 epsilon 0.01\n",
      "episode  95 score -40.00 average score -21.25 epsilon 0.01\n",
      "episode  96 score -16.00 average score -21.20 epsilon 0.01\n",
      "episode  97 score -8.00 average score -21.06 epsilon 0.01\n",
      "episode  98 score -10.00 average score -20.95 epsilon 0.01\n",
      "episode  99 score -24.00 average score -20.98 epsilon 0.01\n",
      "episode  100 score -32.00 average score -20.64 epsilon 0.01\n",
      "episode  101 score -32.00 average score -19.76 epsilon 0.01\n",
      "episode  102 score 16.00 average score -18.80 epsilon 0.01\n",
      "episode  103 score -16.00 average score -18.72 epsilon 0.01\n",
      "episode  104 score 56.00 average score -17.36 epsilon 0.01\n",
      "episode  105 score -32.00 average score -16.88 epsilon 0.01\n",
      "episode  106 score 22.00 average score -16.10 epsilon 0.01\n",
      "episode  107 score 16.00 average score -15.62 epsilon 0.01\n",
      "episode  108 score 0.00 average score -15.06 epsilon 0.01\n",
      "episode  109 score 40.00 average score -14.18 epsilon 0.01\n",
      "episode  110 score -16.00 average score -13.86 epsilon 0.01\n",
      "episode  111 score -24.00 average score -13.86 epsilon 0.01\n",
      "episode  112 score 0.00 average score -13.62 epsilon 0.01\n",
      "episode  113 score -24.00 average score -13.30 epsilon 0.01\n",
      "episode  114 score 16.00 average score -12.66 epsilon 0.01\n",
      "episode  115 score 6.00 average score -11.80 epsilon 0.01\n",
      "episode  116 score 22.00 average score -11.42 epsilon 0.01\n",
      "episode  117 score -16.00 average score -10.70 epsilon 0.01\n",
      "episode  118 score -16.00 average score -10.30 epsilon 0.01\n",
      "episode  119 score -66.00 average score -10.48 epsilon 0.01\n",
      "episode  120 score -32.00 average score -10.88 epsilon 0.01\n",
      "episode  121 score -56.00 average score -11.66 epsilon 0.01\n",
      "episode  122 score -2.00 average score -11.42 epsilon 0.01\n",
      "episode  123 score -32.00 average score -11.72 epsilon 0.01\n",
      "episode  124 score -16.00 average score -11.72 epsilon 0.01\n",
      "episode  125 score 24.00 average score -11.32 epsilon 0.01\n",
      "episode  126 score -24.00 average score -11.24 epsilon 0.01\n",
      "episode  127 score -18.00 average score -11.58 epsilon 0.01\n",
      "episode  128 score -32.00 average score -12.12 epsilon 0.01\n",
      "episode  129 score -26.00 average score -12.38 epsilon 0.01\n",
      "episode  130 score -82.00 average score -13.04 epsilon 0.01\n",
      "episode  131 score 8.00 average score -13.04 epsilon 0.01\n",
      "episode  132 score -88.00 average score -14.00 epsilon 0.01\n",
      "episode  133 score 8.00 average score -14.08 epsilon 0.01\n",
      "episode  134 score 0.00 average score -13.90 epsilon 0.01\n",
      "episode  135 score -32.00 average score -14.14 epsilon 0.01\n",
      "episode  136 score -64.00 average score -15.10 epsilon 0.01\n",
      "episode  137 score -8.00 average score -14.84 epsilon 0.01\n",
      "episode  138 score -16.00 average score -14.82 epsilon 0.01\n",
      "episode  139 score -32.00 average score -14.66 epsilon 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode  140 score -16.00 average score -14.64 epsilon 0.01\n",
      "episode  141 score -8.00 average score -14.86 epsilon 0.01\n",
      "episode  142 score 0.00 average score -14.30 epsilon 0.01\n",
      "episode  143 score -32.00 average score -14.46 epsilon 0.01\n",
      "episode  144 score -10.00 average score -14.72 epsilon 0.01\n",
      "episode  145 score 8.00 average score -14.94 epsilon 0.01\n",
      "episode  146 score 48.00 average score -13.98 epsilon 0.01\n",
      "episode  147 score 24.00 average score -13.32 epsilon 0.01\n",
      "episode  148 score -8.00 average score -13.38 epsilon 0.01\n",
      "episode  149 score 14.00 average score -12.68 epsilon 0.01\n",
      "episode  150 score -26.00 average score -12.94 epsilon 0.01\n",
      "episode  151 score 38.00 average score -12.94 epsilon 0.01\n",
      "episode  152 score 8.00 average score -13.02 epsilon 0.01\n",
      "episode  153 score 0.00 average score -13.10 epsilon 0.01\n",
      "episode  154 score -8.00 average score -13.02 epsilon 0.01\n",
      "episode  155 score -2.00 average score -12.88 epsilon 0.01\n",
      "episode  156 score -24.00 average score -13.04 epsilon 0.01\n",
      "episode  157 score -24.00 average score -13.60 epsilon 0.01\n",
      "episode  158 score -16.00 average score -13.76 epsilon 0.01\n",
      "episode  159 score -16.00 average score -14.08 epsilon 0.01\n",
      "episode  160 score -8.00 average score -14.00 epsilon 0.01\n",
      "episode  161 score -18.00 average score -13.76 epsilon 0.01\n",
      "episode  162 score 16.00 average score -13.36 epsilon 0.01\n",
      "episode  163 score -24.00 average score -13.68 epsilon 0.01\n",
      "episode  164 score 32.00 average score -13.20 epsilon 0.01\n",
      "episode  165 score -10.00 average score -13.22 epsilon 0.01\n",
      "episode  166 score 0.00 average score -13.14 epsilon 0.01\n",
      "episode  167 score -40.00 average score -13.36 epsilon 0.01\n",
      "episode  168 score -24.00 average score -13.04 epsilon 0.01\n",
      "episode  169 score -8.00 average score -12.72 epsilon 0.01\n",
      "episode  170 score 0.00 average score -12.64 epsilon 0.01\n",
      "episode  171 score -34.00 average score -12.80 epsilon 0.01\n",
      "episode  172 score -40.00 average score -13.20 epsilon 0.01\n",
      "episode  173 score 8.00 average score -13.12 epsilon 0.01\n",
      "episode  174 score -24.00 average score -13.28 epsilon 0.01\n",
      "episode  175 score 8.00 average score -12.48 epsilon 0.01\n",
      "episode  176 score -10.00 average score -12.58 epsilon 0.01\n",
      "episode  177 score -24.00 average score -12.64 epsilon 0.01\n",
      "episode  178 score -24.00 average score -12.72 epsilon 0.01\n",
      "episode  179 score -8.00 average score -12.46 epsilon 0.01\n",
      "episode  180 score 32.00 average score -11.98 epsilon 0.01\n",
      "episode  181 score -48.00 average score -12.06 epsilon 0.01\n",
      "episode  182 score 0.00 average score -11.74 epsilon 0.01\n",
      "episode  183 score -8.00 average score -12.06 epsilon 0.01\n",
      "episode  184 score -56.00 average score -12.70 epsilon 0.01\n",
      "episode  185 score 0.00 average score -12.86 epsilon 0.01\n",
      "episode  186 score 8.00 average score -12.46 epsilon 0.01\n",
      "episode  187 score 8.00 average score -12.38 epsilon 0.01\n",
      "episode  188 score 8.00 average score -11.98 epsilon 0.01\n",
      "episode  189 score -16.00 average score -11.66 epsilon 0.01\n",
      "episode  190 score 16.00 average score -11.10 epsilon 0.01\n",
      "episode  191 score 16.00 average score -10.68 epsilon 0.01\n",
      "episode  192 score -32.00 average score -10.84 epsilon 0.01\n",
      "episode  193 score -40.00 average score -11.16 epsilon 0.01\n",
      "episode  194 score -32.00 average score -11.24 epsilon 0.01\n",
      "episode  195 score -56.00 average score -11.40 epsilon 0.01\n",
      "episode  196 score 22.00 average score -11.02 epsilon 0.01\n",
      "episode  197 score 8.00 average score -10.86 epsilon 0.01\n",
      "episode  198 score -16.00 average score -10.92 epsilon 0.01\n",
      "episode  199 score -26.00 average score -10.94 epsilon 0.01\n",
      "episode  200 score -24.00 average score -10.86 epsilon 0.01\n",
      "episode  201 score -8.00 average score -10.62 epsilon 0.01\n",
      "episode  202 score -24.00 average score -11.02 epsilon 0.01\n",
      "episode  203 score -16.00 average score -11.02 epsilon 0.01\n",
      "episode  204 score -8.00 average score -11.66 epsilon 0.01\n",
      "episode  205 score -8.00 average score -11.42 epsilon 0.01\n",
      "episode  206 score -32.00 average score -11.96 epsilon 0.01\n",
      "episode  207 score 16.00 average score -11.96 epsilon 0.01\n",
      "episode  208 score -32.00 average score -12.28 epsilon 0.01\n",
      "episode  209 score -24.00 average score -12.92 epsilon 0.01\n",
      "episode  210 score 8.00 average score -12.68 epsilon 0.01\n",
      "episode  211 score -2.00 average score -12.46 epsilon 0.01\n",
      "episode  212 score 8.00 average score -12.38 epsilon 0.01\n",
      "episode  213 score -40.00 average score -12.54 epsilon 0.01\n",
      "episode  214 score -40.00 average score -13.10 epsilon 0.01\n",
      "episode  215 score 6.00 average score -13.10 epsilon 0.01\n",
      "episode  216 score 32.00 average score -13.00 epsilon 0.01\n",
      "episode  217 score 0.00 average score -12.84 epsilon 0.01\n",
      "episode  218 score 32.00 average score -12.36 epsilon 0.01\n",
      "episode  219 score 32.00 average score -11.38 epsilon 0.01\n",
      "episode  220 score -48.00 average score -11.54 epsilon 0.01\n",
      "episode  221 score -24.00 average score -11.22 epsilon 0.01\n",
      "episode  222 score 24.00 average score -10.96 epsilon 0.01\n",
      "episode  223 score -32.00 average score -10.96 epsilon 0.01\n",
      "episode  224 score 0.00 average score -10.80 epsilon 0.01\n",
      "episode  225 score -16.00 average score -11.20 epsilon 0.01\n",
      "episode  226 score -32.00 average score -11.28 epsilon 0.01\n",
      "episode  227 score -24.00 average score -11.34 epsilon 0.01\n",
      "episode  228 score -18.00 average score -11.20 epsilon 0.01\n",
      "episode  229 score -8.00 average score -11.02 epsilon 0.01\n",
      "episode  230 score -48.00 average score -10.68 epsilon 0.01\n",
      "episode  231 score 0.00 average score -10.76 epsilon 0.01\n",
      "episode  232 score 32.00 average score -9.56 epsilon 0.01\n",
      "episode  233 score -16.00 average score -9.80 epsilon 0.01\n",
      "episode  234 score -40.00 average score -10.20 epsilon 0.01\n",
      "episode  235 score -16.00 average score -10.04 epsilon 0.01\n",
      "episode  236 score 0.00 average score -9.40 epsilon 0.01\n",
      "episode  237 score -58.00 average score -9.90 epsilon 0.01\n",
      "episode  238 score -8.00 average score -9.82 epsilon 0.01\n",
      "episode  239 score -2.00 average score -9.52 epsilon 0.01\n",
      "episode  240 score 24.00 average score -9.12 epsilon 0.01\n",
      "episode  241 score -8.00 average score -9.12 epsilon 0.01\n",
      "episode  242 score -48.00 average score -9.60 epsilon 0.01\n",
      "episode  243 score -64.00 average score -9.92 epsilon 0.01\n",
      "episode  244 score -40.00 average score -10.22 epsilon 0.01\n",
      "episode  245 score 38.00 average score -9.92 epsilon 0.01\n",
      "episode  246 score -56.00 average score -10.96 epsilon 0.01\n",
      "episode  247 score -8.00 average score -11.28 epsilon 0.01\n",
      "episode  248 score 6.00 average score -11.14 epsilon 0.01\n",
      "episode  249 score -16.00 average score -11.44 epsilon 0.01\n",
      "episode  250 score 0.00 average score -11.18 epsilon 0.01\n",
      "episode  251 score -34.00 average score -11.90 epsilon 0.01\n",
      "episode  252 score -56.00 average score -12.54 epsilon 0.01\n",
      "episode  253 score 24.00 average score -12.30 epsilon 0.01\n",
      "episode  254 score -16.00 average score -12.38 epsilon 0.01\n",
      "episode  255 score -50.00 average score -12.86 epsilon 0.01\n",
      "episode  256 score -40.00 average score -13.02 epsilon 0.01\n",
      "episode  257 score -50.00 average score -13.28 epsilon 0.01\n",
      "episode  258 score -8.00 average score -13.20 epsilon 0.01\n",
      "episode  259 score -58.00 average score -13.62 epsilon 0.01\n",
      "episode  260 score -64.00 average score -14.18 epsilon 0.01\n",
      "episode  261 score -32.00 average score -14.32 epsilon 0.01\n",
      "episode  262 score 40.00 average score -14.08 epsilon 0.01\n",
      "episode  263 score -10.00 average score -13.94 epsilon 0.01\n",
      "episode  264 score -32.00 average score -14.58 epsilon 0.01\n",
      "episode  265 score 0.00 average score -14.48 epsilon 0.01\n",
      "episode  266 score 8.00 average score -14.40 epsilon 0.01\n",
      "episode  267 score 8.00 average score -13.92 epsilon 0.01\n",
      "episode  268 score -24.00 average score -13.92 epsilon 0.01\n",
      "episode  269 score -8.00 average score -13.92 epsilon 0.01\n",
      "episode  270 score 0.00 average score -13.92 epsilon 0.01\n",
      "episode  271 score 32.00 average score -13.26 epsilon 0.01\n",
      "episode  272 score -40.00 average score -13.26 epsilon 0.01\n",
      "episode  273 score 30.00 average score -13.04 epsilon 0.01\n",
      "episode  274 score 6.00 average score -12.74 epsilon 0.01\n",
      "episode  275 score 6.00 average score -12.76 epsilon 0.01\n",
      "episode  276 score -16.00 average score -12.82 epsilon 0.01\n",
      "episode  277 score -16.00 average score -12.74 epsilon 0.01\n",
      "episode  278 score -64.00 average score -13.14 epsilon 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode  279 score -24.00 average score -13.30 epsilon 0.01\n",
      "episode  280 score -56.00 average score -14.18 epsilon 0.01\n",
      "episode  281 score -16.00 average score -13.86 epsilon 0.01\n",
      "episode  282 score -48.00 average score -14.34 epsilon 0.01\n",
      "episode  283 score -10.00 average score -14.36 epsilon 0.01\n",
      "episode  284 score -10.00 average score -13.90 epsilon 0.01\n",
      "episode  285 score -50.00 average score -14.40 epsilon 0.01\n",
      "episode  286 score -40.00 average score -14.88 epsilon 0.01\n",
      "episode  287 score 22.00 average score -14.74 epsilon 0.01\n",
      "episode  288 score -2.00 average score -14.84 epsilon 0.01\n",
      "episode  289 score -48.00 average score -15.16 epsilon 0.01\n",
      "episode  290 score -72.00 average score -16.04 epsilon 0.01\n",
      "episode  291 score 6.00 average score -16.14 epsilon 0.01\n",
      "episode  292 score 24.00 average score -15.58 epsilon 0.01\n",
      "episode  293 score -40.00 average score -15.58 epsilon 0.01\n",
      "episode  294 score -32.00 average score -15.58 epsilon 0.01\n",
      "episode  295 score 16.00 average score -14.86 epsilon 0.01\n",
      "episode  296 score 32.00 average score -14.76 epsilon 0.01\n",
      "episode  297 score 46.00 average score -14.38 epsilon 0.01\n",
      "episode  298 score -18.00 average score -14.40 epsilon 0.01\n",
      "episode  299 score 46.00 average score -13.68 epsilon 0.01\n",
      "episode  300 score 8.00 average score -13.36 epsilon 0.01\n",
      "episode  301 score -56.00 average score -13.84 epsilon 0.01\n",
      "episode  302 score -8.00 average score -13.68 epsilon 0.01\n",
      "episode  303 score -8.00 average score -13.60 epsilon 0.01\n",
      "episode  304 score -32.00 average score -13.84 epsilon 0.01\n",
      "episode  305 score -8.00 average score -13.84 epsilon 0.01\n",
      "episode  306 score 6.00 average score -13.46 epsilon 0.01\n",
      "episode  307 score -2.00 average score -13.64 epsilon 0.01\n",
      "episode  308 score 32.00 average score -13.00 epsilon 0.01\n",
      "episode  309 score -72.00 average score -13.48 epsilon 0.01\n",
      "episode  310 score 0.00 average score -13.56 epsilon 0.01\n",
      "episode  311 score 22.00 average score -13.32 epsilon 0.01\n",
      "episode  312 score -34.00 average score -13.74 epsilon 0.01\n",
      "episode  313 score -56.00 average score -13.90 epsilon 0.01\n",
      "episode  314 score 16.00 average score -13.34 epsilon 0.01\n",
      "episode  315 score -40.00 average score -13.80 epsilon 0.01\n",
      "episode  316 score 6.00 average score -14.06 epsilon 0.01\n",
      "episode  317 score -32.00 average score -14.38 epsilon 0.01\n",
      "episode  318 score -24.00 average score -14.94 epsilon 0.01\n",
      "episode  319 score -16.00 average score -15.42 epsilon 0.01\n",
      "episode  320 score -34.00 average score -15.28 epsilon 0.01\n",
      "episode  321 score -40.00 average score -15.44 epsilon 0.01\n",
      "episode  322 score 16.00 average score -15.52 epsilon 0.01\n",
      "episode  323 score 22.00 average score -14.98 epsilon 0.01\n",
      "episode  324 score 32.00 average score -14.66 epsilon 0.01\n",
      "episode  325 score -18.00 average score -14.68 epsilon 0.01\n",
      "episode  326 score -88.00 average score -15.24 epsilon 0.01\n",
      "episode  327 score -56.00 average score -15.56 epsilon 0.01\n",
      "episode  328 score -18.00 average score -15.56 epsilon 0.01\n",
      "episode  329 score 8.00 average score -15.40 epsilon 0.01\n",
      "episode  330 score 24.00 average score -14.68 epsilon 0.01\n",
      "episode  331 score 0.00 average score -14.68 epsilon 0.01\n",
      "episode  332 score 48.00 average score -14.52 epsilon 0.01\n",
      "episode  333 score 6.00 average score -14.30 epsilon 0.01\n",
      "episode  334 score -16.00 average score -14.06 epsilon 0.01\n",
      "episode  335 score -40.00 average score -14.30 epsilon 0.01\n",
      "episode  336 score -24.00 average score -14.54 epsilon 0.01\n",
      "episode  337 score 0.00 average score -13.96 epsilon 0.01\n",
      "episode  338 score 0.00 average score -13.88 epsilon 0.01\n",
      "episode  339 score -34.00 average score -14.20 epsilon 0.01\n",
      "episode  340 score 0.00 average score -14.44 epsilon 0.01\n",
      "episode  341 score -32.00 average score -14.68 epsilon 0.01\n",
      "episode  342 score -24.00 average score -14.44 epsilon 0.01\n",
      "episode  343 score 16.00 average score -13.64 epsilon 0.01\n",
      "episode  344 score -18.00 average score -13.42 epsilon 0.01\n",
      "episode  345 score -32.00 average score -14.12 epsilon 0.01\n",
      "episode  346 score -24.00 average score -13.80 epsilon 0.01\n",
      "episode  347 score -24.00 average score -13.96 epsilon 0.01\n",
      "episode  348 score -32.00 average score -14.34 epsilon 0.01\n",
      "episode  349 score -16.00 average score -14.34 epsilon 0.01\n",
      "episode  350 score -18.00 average score -14.52 epsilon 0.01\n",
      "episode  351 score -2.00 average score -14.20 epsilon 0.01\n",
      "episode  352 score 22.00 average score -13.42 epsilon 0.01\n",
      "episode  353 score -64.00 average score -14.30 epsilon 0.01\n",
      "episode  354 score -8.00 average score -14.22 epsilon 0.01\n",
      "episode  355 score -24.00 average score -13.96 epsilon 0.01\n",
      "episode  356 score -8.00 average score -13.64 epsilon 0.01\n",
      "episode  357 score -58.00 average score -13.72 epsilon 0.01\n",
      "episode  358 score -56.00 average score -14.20 epsilon 0.01\n",
      "episode  359 score -32.00 average score -13.94 epsilon 0.01\n",
      "episode  360 score -16.00 average score -13.46 epsilon 0.01\n",
      "episode  361 score 6.00 average score -13.08 epsilon 0.01\n",
      "episode  362 score 8.00 average score -13.40 epsilon 0.01\n",
      "episode  363 score 8.00 average score -13.22 epsilon 0.01\n",
      "episode  364 score 0.00 average score -12.90 epsilon 0.01\n",
      "episode  365 score -32.00 average score -13.22 epsilon 0.01\n",
      "episode  366 score 6.00 average score -13.24 epsilon 0.01\n",
      "episode  367 score -24.00 average score -13.56 epsilon 0.01\n",
      "episode  368 score 16.00 average score -13.16 epsilon 0.01\n",
      "episode  369 score -24.00 average score -13.32 epsilon 0.01\n",
      "episode  370 score -2.00 average score -13.34 epsilon 0.01\n",
      "episode  371 score -26.00 average score -13.92 epsilon 0.01\n",
      "episode  372 score -16.00 average score -13.68 epsilon 0.01\n",
      "episode  373 score -18.00 average score -14.16 epsilon 0.01\n",
      "episode  374 score -24.00 average score -14.46 epsilon 0.01\n",
      "episode  375 score 32.00 average score -14.20 epsilon 0.01\n",
      "episode  376 score -32.00 average score -14.36 epsilon 0.01\n",
      "episode  377 score -10.00 average score -14.30 epsilon 0.01\n",
      "episode  378 score -16.00 average score -13.82 epsilon 0.01\n",
      "episode  379 score 0.00 average score -13.58 epsilon 0.01\n",
      "episode  380 score 40.00 average score -12.62 epsilon 0.01\n",
      "episode  381 score -8.00 average score -12.54 epsilon 0.01\n",
      "episode  382 score -8.00 average score -12.14 epsilon 0.01\n",
      "episode  383 score 0.00 average score -12.04 epsilon 0.01\n",
      "episode  384 score -16.00 average score -12.10 epsilon 0.01\n",
      "episode  385 score -16.00 average score -11.76 epsilon 0.01\n",
      "episode  386 score -16.00 average score -11.52 epsilon 0.01\n",
      "episode  387 score -8.00 average score -11.82 epsilon 0.01\n",
      "episode  388 score -56.00 average score -12.36 epsilon 0.01\n",
      "episode  389 score 0.00 average score -11.88 epsilon 0.01\n",
      "episode  390 score -16.00 average score -11.32 epsilon 0.01\n",
      "episode  391 score 0.00 average score -11.38 epsilon 0.01\n",
      "episode  392 score -56.00 average score -12.18 epsilon 0.01\n",
      "episode  393 score 0.00 average score -11.78 epsilon 0.01\n",
      "episode  394 score -48.00 average score -11.94 epsilon 0.01\n",
      "episode  395 score -32.00 average score -12.42 epsilon 0.01\n",
      "episode  396 score 6.00 average score -12.68 epsilon 0.01\n",
      "episode  397 score -8.00 average score -13.22 epsilon 0.01\n",
      "episode  398 score 16.00 average score -12.88 epsilon 0.01\n",
      "episode  399 score 8.00 average score -13.26 epsilon 0.01\n",
      "episode  400 score -56.00 average score -13.90 epsilon 0.01\n",
      "episode  401 score -24.00 average score -13.58 epsilon 0.01\n",
      "episode  402 score -42.00 average score -13.92 epsilon 0.01\n",
      "episode  403 score 0.00 average score -13.84 epsilon 0.01\n",
      "episode  404 score -24.00 average score -13.76 epsilon 0.01\n",
      "episode  405 score 16.00 average score -13.52 epsilon 0.01\n",
      "episode  406 score -16.00 average score -13.74 epsilon 0.01\n",
      "episode  407 score -10.00 average score -13.82 epsilon 0.01\n",
      "episode  408 score -18.00 average score -14.32 epsilon 0.01\n",
      "episode  409 score 32.00 average score -13.28 epsilon 0.01\n",
      "episode  410 score -18.00 average score -13.46 epsilon 0.01\n",
      "episode  411 score -8.00 average score -13.76 epsilon 0.01\n",
      "episode  412 score 14.00 average score -13.28 epsilon 0.01\n",
      "episode  413 score -8.00 average score -12.80 epsilon 0.01\n",
      "episode  414 score -32.00 average score -13.28 epsilon 0.01\n",
      "episode  415 score 38.00 average score -12.50 epsilon 0.01\n",
      "episode  416 score 16.00 average score -12.40 epsilon 0.01\n",
      "episode  417 score 0.00 average score -12.08 epsilon 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "episode  418 score -40.00 average score -12.24 epsilon 0.01\n",
      "episode  419 score -40.00 average score -12.48 epsilon 0.01\n",
      "episode  420 score 24.00 average score -11.90 epsilon 0.01\n",
      "episode  421 score -8.00 average score -11.58 epsilon 0.01\n",
      "episode  422 score -10.00 average score -11.84 epsilon 0.01\n",
      "episode  423 score 8.00 average score -11.98 epsilon 0.01\n",
      "episode  424 score 6.00 average score -12.24 epsilon 0.01\n",
      "episode  425 score 16.00 average score -11.90 epsilon 0.01\n",
      "episode  426 score -32.00 average score -11.34 epsilon 0.01\n",
      "episode  427 score -40.00 average score -11.18 epsilon 0.01\n",
      "episode  428 score -24.00 average score -11.24 epsilon 0.01\n",
      "episode  429 score -10.00 average score -11.42 epsilon 0.01\n",
      "episode  430 score 0.00 average score -11.66 epsilon 0.01\n",
      "episode  431 score 24.00 average score -11.42 epsilon 0.01\n",
      "episode  432 score -48.00 average score -12.38 epsilon 0.01\n",
      "episode  433 score 6.00 average score -12.38 epsilon 0.01\n",
      "episode  434 score -24.00 average score -12.46 epsilon 0.01\n",
      "episode  435 score 8.00 average score -11.98 epsilon 0.01\n",
      "episode  436 score -8.00 average score -11.82 epsilon 0.01\n",
      "episode  437 score -10.00 average score -11.92 epsilon 0.01\n",
      "episode  438 score 8.00 average score -11.84 epsilon 0.01\n",
      "episode  439 score 16.00 average score -11.34 epsilon 0.01\n",
      "episode  440 score -26.00 average score -11.60 epsilon 0.01\n",
      "episode  441 score 32.00 average score -10.96 epsilon 0.01\n",
      "episode  442 score -24.00 average score -10.96 epsilon 0.01\n",
      "episode  443 score 6.00 average score -11.06 epsilon 0.01\n",
      "episode  444 score 0.00 average score -10.88 epsilon 0.01\n",
      "episode  445 score -40.00 average score -10.96 epsilon 0.01\n",
      "episode  446 score -16.00 average score -10.88 epsilon 0.01\n",
      "episode  447 score -66.00 average score -11.30 epsilon 0.01\n",
      "episode  448 score 24.00 average score -10.74 epsilon 0.01\n",
      "episode  449 score -48.00 average score -11.06 epsilon 0.01\n",
      "episode  450 score -34.00 average score -11.22 epsilon 0.01\n",
      "episode  451 score -8.00 average score -11.28 epsilon 0.01\n",
      "episode  452 score 14.00 average score -11.36 epsilon 0.01\n",
      "episode  453 score 0.00 average score -10.72 epsilon 0.01\n",
      "episode  454 score -32.00 average score -10.96 epsilon 0.01\n",
      "episode  455 score -8.00 average score -10.80 epsilon 0.01\n",
      "episode  456 score 8.00 average score -10.64 epsilon 0.01\n",
      "episode  457 score -24.00 average score -10.30 epsilon 0.01\n",
      "episode  458 score 30.00 average score -9.44 epsilon 0.01\n",
      "episode  459 score 0.00 average score -9.12 epsilon 0.01\n",
      "episode  460 score 14.00 average score -8.82 epsilon 0.01\n",
      "episode  461 score -2.00 average score -8.90 epsilon 0.01\n",
      "episode  462 score -24.00 average score -9.22 epsilon 0.01\n",
      "episode  463 score 38.00 average score -8.92 epsilon 0.01\n",
      "episode  464 score -56.00 average score -9.48 epsilon 0.01\n",
      "episode  465 score -24.00 average score -9.40 epsilon 0.01\n",
      "episode  466 score 14.00 average score -9.32 epsilon 0.01\n",
      "episode  467 score -16.00 average score -9.24 epsilon 0.01\n",
      "episode  468 score -34.00 average score -9.74 epsilon 0.01\n",
      "episode  469 score -42.00 average score -9.92 epsilon 0.01\n",
      "episode  470 score -34.00 average score -10.24 epsilon 0.01\n",
      "episode  471 score 0.00 average score -9.98 epsilon 0.01\n",
      "episode  472 score -18.00 average score -10.00 epsilon 0.01\n",
      "episode  473 score -16.00 average score -9.98 epsilon 0.01\n",
      "episode  474 score -10.00 average score -9.84 epsilon 0.01\n",
      "episode  475 score 16.00 average score -10.00 epsilon 0.01\n",
      "episode  476 score 0.00 average score -9.68 epsilon 0.01\n",
      "episode  477 score -24.00 average score -9.82 epsilon 0.01\n",
      "episode  478 score -2.00 average score -9.68 epsilon 0.01\n",
      "episode  479 score -16.00 average score -9.84 epsilon 0.01\n",
      "episode  480 score -32.00 average score -10.56 epsilon 0.01\n",
      "episode  481 score -48.00 average score -10.96 epsilon 0.01\n",
      "episode  482 score 0.00 average score -10.88 epsilon 0.01\n",
      "episode  483 score -40.00 average score -11.28 epsilon 0.01\n",
      "episode  484 score 0.00 average score -11.12 epsilon 0.01\n",
      "episode  485 score -80.00 average score -11.76 epsilon 0.01\n",
      "episode  486 score -16.00 average score -11.76 epsilon 0.01\n",
      "episode  487 score 16.00 average score -11.52 epsilon 0.01\n",
      "episode  488 score -8.00 average score -11.04 epsilon 0.01\n",
      "episode  489 score -16.00 average score -11.20 epsilon 0.01\n",
      "episode  490 score -48.00 average score -11.52 epsilon 0.01\n",
      "episode  491 score -2.00 average score -11.54 epsilon 0.01\n",
      "episode  492 score 40.00 average score -10.58 epsilon 0.01\n",
      "episode  493 score -24.00 average score -10.82 epsilon 0.01\n",
      "episode  494 score 14.00 average score -10.20 epsilon 0.01\n",
      "episode  495 score -34.00 average score -10.22 epsilon 0.01\n",
      "episode  496 score -2.00 average score -10.30 epsilon 0.01\n",
      "episode  497 score -42.00 average score -10.64 epsilon 0.01\n",
      "episode  498 score -16.00 average score -10.96 epsilon 0.01\n",
      "episode  499 score -16.00 average score -11.20 epsilon 0.01\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAawAAAEGCAYAAAA5T6EkAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA0wElEQVR4nO3df5wddX3v8dfZzdlkE8kkafxJYie0sS3Q1VtW1P7SGrXQAaO0XdH+8Nc1olCKeB9yrPcRp/TSx2ARxAqlESzY1tJtRRsyKkraSnuFK8GLq0DVlMwlEavGyAHCkt3snvvHnMnOnp2ZM3POmT0/5v18PPLInjlz9sw5e8585vv9fr6fb6lWqyEiItLrhrp9ACIiImkoYImISF9QwBIRkb6ggCUiIn1BAUtERPrCim4fQFYbN26smabZ7cMQEekr99133+FarfbMbh9HO/ouYJmmyb59+7p9GCIifaVUKv2/bh9Du9QlKCIifUEBS0RE+kJuXYJmxf0EcA7wA8+xTo+4vwRcC/wG8BTwFs+xvpbX8YiISH/Ls4V1M3BWwv1nA1vr/3YAf5HjsYiISJ/LLWB5jnUXcCRhl+3AJz3HqnmOdQ+wzqy4z83reEREpL91M0vwZOBg6Pah+rbvNe5oVtwd+K0who7OLMvBSY6mJuHzl8F0/XpmdAOcfSWMTXT3uESKzjbOwh+qGQZuxK46XT6iRboZsEoR2yJLx3uOtQvYBTB+5wdVXr6fTU3CZ98N87ML26aPwG3vgEfugXOu7t6xiRSZbQwD1wGvxm9A3Itt7MauPtjdA1vQzSzBQ8Dm0O1NwKN5Pdm3/usJrrrjWxxRC6279l6+OFiF7fuEH9BEpBvOBPZjVx/Grs4At+IP3fSMbgas3cDvmxW3ZFbclwJVz7GWdAd2yoHDT/Kxf9nPf1WfzuspJI3qoYQ7a35AE5FuiBum6Rl5prX/HfAKYKNZcQ8BHwTKAJ5j3QB8Dj+lfT9+Wvtb8zoWgJNWlQF44umYq3tZHqPrF8auoiQGNMlkatK/AKgeAmMTbNupcUIo7Pvy3peNbMQ2wmWCdmFXd4Vupx6m6ZbcApbnWG9scn8NuDCv52900ir/pT7x9PHlesr+MDUJt18Cs0f926UhOOOt+YwlTU3CsSeS9zE2df55i2hqEm6/GGan/dvVg/5tKMTJOVaB35cP3z1z+KqvHBtP2GVZh2laUZhKFydaWMfUwjphahJue+dCsAKozcO+m2DPpZ1/vqTxK4DyqH+1K+3be/nCSTkwO60uV70vSe4FtmIbW7CNEeB8/KGbnlGggKUW1hJ7Lwfmo++77+bOP1/1YPx9xmY496MDf5W7bOK6Vove5ar3JZ5dPQ5cBNwBPARMYlcf6O5BLdZ31dpbpYAVIelLWpvr3PME866SFGQcYdkYm6IvEIre5ar3JZld/Rx+fkFPKkwLa+WKYUZWDPG4ki4WJH1JS8OdeY5gzCAp0QLUJdNp23b6XayLlGDra7pyOD1hahKeivgcDpXVFd0nChOwANauWqEWVti2ncR+BM54S2eeI2rMIEr1oOZgddLYBLzwTSxO/KrB1z9VzPc5mLAeHq89IaZbXHpOoQLWSavKPD6tFtYJYxMwHjWboOQnXlxzensnt6nJ5HGrRrdfXMyTaV6+80WWZCXPTjfvnh1ESQk/83N+pZV2P++Su8KMYYE/jpVbC6sf53ZMTfpX3EvUT3LtpPwGXYFZBNlavf6+9boTn8WYi4XpI34WaC+Vwcr7+5MmqSL8eYeF97A07I/pGpv743s9wAoYsHJoYU1Nwj9dCHP1sk/Vg/4V223viP+QR51USsN+V9xynUjSdNe1GkTSdgU2UrZWexo/i3H23QTPf2lvnHz3XOqX5erEhVJYY5HlNIIW6MyTC+9hkIBUPeh3K7Z7XNKyQnUJrl1VzqeF9fnL4k8QwZcv3NUQtD4ar4Brc/nNgYo7tlT7tRBEsnQFhnUrW2tq0u8Sstf1d9dQ0mcxat9um5pcHKwC7c6NCsassgSrwPSR+PdwfrY33reCKlTAyq1LsNmXovHL16z1se8TnTmuJFOTRFdiidBKEEmTZbgkiw3YcEr252rXnkvhth31IFurt5B3LN+FQydlOUG3cjLvtL2XE1v9p9WLnuD3Jk1Sb0cvvG8FVbCAVe5eLcFwK6XpF7GW/8lyzyWkLhPWSip0s3lcxmbYdObS7Qe+DLe8NvvztWJqEq7c4rdql7wXteVt7RZVs9Z7qy1ddS0PpIIFrBUcnZljbr6D9RzTfqHKq0P7p2jZ7LvJP5nm0TW151KYiUrvjfF//zr7cRibE+4s+eN63r9H333gy/kHirTzw/bdBLYBf7zB/7/XuwvLa9LvO7ohv+NIq1nr/TPvbO39zrNruRfet4IqWMDy6wk+2cluwbT92bNHFxIt0rZspo/k0zV1319l239uJvt4wrad/oTMKONv8wetk1phea+NlTUppHHgvReD1tRk+vGr4RF/ledu27aTxAu42jx85oLs73eeE6Snj0RfuAQtdtvw/13xvPrtdb1/odMnChaw/KTIjla7yNKf/fnLWuiqqHX25D016Z8Esso6njA2Aa+7fvHV6OgGOO/jC1mQieNcKdbG2nPpQsvnjzdkC+ztdBn16sB7lnGbkWfkeyxpjU34FzBJanPZ3+/vfLH1Y0qjMZkqKslj9mj9dm0hc1hBrC2FClhru11PMPjwZtbBhQ3b+T1ZAsKeS/0r4+kjfmAafztcdmBxOnCzahpJQeWW1/rddUHLJ2uGZbtdRr028J51kvb0kWwTtRtbD53srn7+S5t3ZWZ9v9NckJTaPP3NTi8Eodveke5iYUkQ69Pkni4pVMAKugQ72sJarv7sTg0iJ53Utrw8vhsP0ldw33NpumByztX+c8YZXR+dar7nUn+cq9VjjKsp169amaQN8anjjSn+ey5d2nqYPuLP92o3aJ1YnyrDmGoaaS5IzF+JzlTNqq1j73APyoArWMDqcAtrOT9knRpETuqGe/NuvxsvTtoK7nFBI2r7m3f7ra/GcYyhsj95M5xqfvvFoUmmLR5jYk25DPK8UMk6J6zVSdqw9EJo0RzB+vu+76bo1sPcjN+yyNodG5bl2LO06iKL/zY48rC/pE2nCj23rIM9KAOuYJUu6os4dqKF1bhyad46NYjc7IQ+NuF35UXul3LeVtxzxG0/52q/Wyhcmmfm6NJuoNnpesJIk25V2/CTCkaeAdM/Xlzqp1Pzc/JKWAgCanCMaaortNP6Dlqx4fc962c6aEFD9iotWY49aNU9co8/RhVXxilIbpqdxv/Mxs3zOrTwuPB73g1Kw0+lUC2sjo5htXNV24oHPtP+70hKqQ+noceNLQ0NpbvCjbtiTbqSHZuA93wT7Mf8/6d/HL1f2oSRuZnFYwXBeE1HTgylzpfmCVpVUWMhzZI80rS+h8p+EG/c1tiKbWdsrpVFP7P2HMzN+MGxseUdTn5YVEUm4eImeO4gQaibRtd39/n7RKECVkdbWJ2+IiqvSR4EDgqWtiM2pb60eD2gc66GkYhB8Pm5dF0XcQEvKcmicVC/lLI1l9bstN9yTDwxlNKNaTTLassqrlRXWFwgmZqEJ76f/PuNzf4Jeft19QuTkv//ipH0afBp1Oayd5On6bprJjwWl+VCMvyZH5toMncwZzNPahwrhUIFrJEVQ6xcMdSZFlazK0Njs5/Cfd7H0/2+DzwKr/9LErvd2h2cjQ2ytaUthpmnMv6OkHOu9selghZVkCUY110UlRLcSup9M7U5OPZE0g7+mEbc+FRpKPl1tKrV1vqJ7sOEoFMa9luswd935ignWiZZJo+n1UoixopQwBrd0Nr4YPC5THshObph6We+E8GzVa3MdSygQgUsqK+J1YmAlbhCack/SUC6+SPBib3pnJQ2B2fjgmzUlWXsvim7cM65Gj54BOyq/3/SST7Pum+N5mfjW7LGZv9vcNkB/0Ij3BoZfzusPdm/aOj0/Jk06ehRJ/E071vQqm2nGGwWWU68UdVGjk/Daa/P/rzB5zLN57M8Gj0GOTbhX7CE/+5pLzg7QeNYTRUuYK3t1BIjYxPxV4LGpmwniHBX2TlXJ19htvOhjrqCLI9GB9+oShV5LSW+3F/U2nzz9yE8prZtp79u2KLiuO+AP31eZwJXmiy1uWNLn6vZ+1Zes3ChsJwXBWn/nlEty9lpP6Fi/O3ZnnPbTv/9adZqNDb7QSluDLJxLHU5uwq7tVJBHylcwOpoxfazr4w/8aU5QcR1MZ19JfHJEW18qKOuIJO+vI3jSJ0eVwos9xc1eN1p34e4LruZo52Zi5RmukDUczUbjzv3Iws3U18UdOBvnCaBIGmic/WQ/5047+Ppj+eRe1LUhiwt7h5Na7m6ChszgQdlyZsOKmDA6mDF9qQAkHiCKNW7yn4c3VV2omuw8ctaai+9Pag+UT3oB8utr0k+STcOyM/N5FOSKKnuYB6e/P5Cmaw0q9sm/S3bfU+mJtNXXMjS3RbUawykuSgoDbdf/SGNZhOdw9l75+1K9zvvu7n5OGCrF0aLvucJRjcQG2CDcdyk3xEuJxU1Hy5LZZIBVcCA1eE1saK6ECD5y5Hmi3PO1bDlVxs21uBrn2ztQ5u2+kQg7iQ9faTzX5rlTiuOS3mP0+zv1ep7EnQbZ0kwCbdK4lL/YemFUJqLgtpck9ZeqV6ZpEmrJ+64wqn7ccFlaHhp12waaVqp7XRnn/ieV5eOb573cX/7ZQf8ABvV6/L6G/y/yXu+Sez7F/7Off6y6O7SgidmFDJgdbQ0U5y4E8TwSLovztRkdPmhVgqvTk0uTOxsFDd3JukknfSlabXm3NjE8g5whzU7EaT5e+29vLUKFVnHlcLjXVmSaKKKEWd7Ytj4M/XPZJOJ21HHlSZ1H2B+fmmQ6kRVkaiswFbFXaQG9zXrbm6W0DQ1Gd+12c6ilgOggAGr3NnSTHEnqLhq5duvS/fFSTqBZsn0atb9EndlmnSSjmt9RSWaZKk5FwStLGs6wcLJoZ0SO0ndfmMT0fPSFj3+YPYunFaSTcJ/ryxJNLCQAZk1AJSG/ZbDj77TfN+4599zScrU/Yhg2KyqSOOE6CVKy7uUSlJAg+Z/t8QL0pzGkftE4QLW2lVlnpqZ4/hcm/N80vQxBycIu7rQZZD2Kq9TmXPN5vjEneSbZUHGPVdczbm0XRljE/6ctOA9s6vJJ9jRDQsnh9ff0PrgeLNuv7h5aYHSUPYunFbHVIJu3KxJNIHjx7I93+tvaL5+WdLzZ1kwNOrzmPRZLA2FJkTHaBzP67bg7xa+MDt+zE8cgSYXpLVCj2MVL2CNdqg8U1xKbqf6mJNOZkMj6buemnUhJFWfSMqCjHyuhCDbTgBOGqsJXzlHncCbtYwgXTdts+ASNw6V9LpbHVPZd9PC37zZ1XyjqcnshX+D35lUcivp+bOUbIr7PEZ9Fin57/vey/0Eoqj785jo3QmP3LP471Cb9/+ut7y2+WMLPI5VuIBljPrjStXpNsex4k5EnWoZJQ2Sz8+k63pKqh0I/gB60pc56xV8u4kmWR8bNS7ReAJv1jICv0husxN9s5Vx4yS97sRWbJOMtFYzE7Oe7MJBqlnJrbgu8rRV/iH+87gkUy9U1LZ60E9GCp/ORjf43Zi9GKwgPojHLZsTVuAJxrlWazcr7lnAtcAwcKPnWE7D/QbwN8Dz68dyledYGddvz2Ztp9bEGl0f3XTv1Jyi4AT6mXc2zyKbnfZPYI0n3djagXVHHk53HGm7U7btjK70njbRJOn3NlbGj6tW0MjY1LyVmdSCC4xN+FfF+z5BpkU4m73us6+Mfm3bdvrZdHGCzMSsXV1ZT3aNk9rBP9nW5vxgdsZb/Er7V25Z/H0ILqSAxIrpYc2CdPBZvOb0pX/T+dnF3dGJJbh6QJYg3qi8unPH0Wdya2GZFXcYuA44GzgVeKNZcU9t2O1C4EHPsV4IvAL4sFlxm42gtmVtvYX1+HQbXYJTk9FfiHZPzI3GJqCW8uQ4fcS/sg2nqTc7UXf6Su2Re6K/iP/t99obQ2h1rAbSTfrMUm7qvF3pKx+U1yQfY3gZjKAlE35tzZIjWukainutjfOv4uo/Npbcev5L4yu6BCvypglWWb47aT63rWTTLqd2EoRmj6brOhxAeXYJngns9xzrYc+xZoBbge0N+9SAk8yKWwKeARwBcl2/viNdgnHJBWm6lrLK1GKr+f3gf/Ks+oTUJl+KTlaYmJqMX1gxPCGyVVnHasKPSypom/UiIziONJJOLEFGZXBRUZtbKH0VvLazryTxK1o96C+eaBvpF1GM62oOt+KHygvzhpr5/GWdKfmU5buT9nObd93EdiSNHadx4MuFTL7IM2CdDIQv8Q/Vt4V9DPg54FHgG8Afeo6VQ5nuBUHSRVtdgrGTalN0LWXVShWIuWP+lW2zrK60J+o084uSuh+73eceLmjb6jSDsCwnigNfXhy0sqx7NTYB5/1lcvWJtBPBw5qV2MrSOulUUMjy3cmjnuVyO+fq+iTsNhQw+SLPMayob0XjGe3XgfuBVwI/BXzJrLj/5jnW4+GdzIq7A9gBMHS0vfV7gjGstlpYceMiedTEG5vwTx6dvlpMm+rbuLJyeGwi/PikoNQrRT2zjMclydrVFL4abrZKdePfOTjetKtb33dz88r4adbAWu7WSZbPyNhE8vheoBMTjvP05t1Lx/6y6PaFYBfk2cI6BIQ7+zfht6TC3grc5jlWzXOs/cAB4Gcbf5HnWLs8xxr3HGt8w5r2hrhWjwyzYqjE4+0ErLh6fp1axr5RR1tuGVN906bvx55wMrTk+kUrJ5jPvDO63E4azbo1w5oN5nf6JNeJoJA0VaLV5x0aXt7Jwq1q57vdKxeCyyjPgHUvsNWsuFvqiRTnA7sb9nkE2AZgVtxnAz8DpEhda12pVGLtaLm9LsG4MZlOjNVE6eTy2eNvy5bqG1tR++DirrGtryGyWG+vTdrsltp8ukAXdyJ+5J50J7dOjlum6fpsJSgMjbSWQJPleV93Q3987lJ9tyP+pq0E+XbYxp9hG/+BbUxhG5/BNtaF7ns/trEf2/gWtvHreR5GbgHLc6zjwEXAHcBDwKTnWA+YFfcCs+JeUN/tT4BfNCvuN4C9wGWeYx3O65gCa1etoNpOlmDec7DylDWoJp0Ag/lfU5P+elGLenxL2YNjv8izqynqRHwioSVFtl2zwfwsS2WkGSMZm8i+dtX8bGsJNI3PmzSHrR+CVVrn3bC04G4rQb49XwJOx66OAd8G3g+AbZyK3xg5DTgLuB7baCMFMlmu87A8x/oc8LmGbTeEfn4UyKkfLZ4xWm6vSzDvOViNEq+sS35V9zQTDiF7UE3qYgp3DS7p6qrl1+LstrOvjJ9vtv4UOPwfrf3euAKtzebTgZ+YccZbm18gBL9/7+ULy6skrUuVxjlX++ntacdaO/U9SZrD1i+atZrH377wN+tmELar4S/zPcBv1X/eDtyKXT0GHMA29uNniN+dx2HkGrB61drRcutJF8s1BysscfJrLdvgbdaThbE5eT5X9RDx2YEDWlk6OHGET9CjG/wT6NhE6wPpcd1caQLHipV+0EijMfkkaiIuZE+EgObJIZ0MKFHBt9naZr0m6bvdrBJNRu992chGbGNfaNMu7GrKBccWeRvw9/WfT8YPYIGobPCOKWzA+u5jLQx+w/LOwQo0q3oAcNrr45cQCbRysoiqMrHod66Or03XzuTIXpeUcXj2lXDbO4EMMzSSlr9IU60jaO228hmMqySS9bOSptByp7uyOpX52S1x368tL/cvRDvow3fPHL7qK8fGY3ewjTuB50Tc8wHs6j/V9/kA/lzZv63flyYbvGOKGbBWlVuvdBF34shjDlZgbAJuvyQ6MAT9+HHdb6Vhf8C/1avPEyWJYoJhUiHVdsrP9LtSKcPXtsnyF80uGgKtjqF2qqXS7PlrEWtdFV0vtRLt6quS7zfeDJwDbMOuBp/uNNngHVPMgDW6gsenZ6nVapSaTaIMO1FMNuJMlHeK6bkf8SsjhFt3Q+WFE13cyaI27w9ut6PVsai0JYwGzd7LMwbrWvIJatFJLaGl1c5nsBMtlbix3UAB07BT6YdWom2cBVwGvBy7Gq4ovRv4FLZxNfA8YCvw1bwOo3DV2sFPupiZm+fY8YxFNWIHv5dhrlGwIGQ4U+h11y980JutYtqOlq7cB3D+VVpZ3680gT0oCZWUodjT73eBPw+D4WPAScCXsI37sQ0/ec6uPgBMAg8CXwAuxK7m1rVSzBZWULF9epZV5QzjLLEnoiZXyJ2SdCXWqXGIKGnGUJZYpvekF2V5v7L+jZJaMN1+v5O6xTUfr7/Z1Z9OuO8K4IrlOIxCtrDWtloAN7YV0wNdX+1UNG8my9ydwCAnXDSTtv7jyJpuzKfJT9K6ZYM4H0+WXSFbWEHF9szVLvJsxXRCXn3hUWnczRQ54SLt+5WUGZj0mKjf2Qt189pZt0wkhWK2sFb5cTpzC2tsAl74poXWQ2nYvz0oV8hJwhXP07Qoe6HV2U3h9ytOK2ODZ1+5tPUWTr7ppjxb+SIUtIXV8iKOQQmi8JIOX/+UP2FTX8oFvdTq7KZgzas4rSTE9FIadJR+yHiTvlXIgNVyl2BS5fIifEkblxqJUhrSVXUgbpI50FbWnIKCFFQhuwRPCroEn8oYsNqtudbvmlUyAFi1TifTQOLnosBZlCItKmTAWrlimFXloWwtrBOThiMUZUJkmsCcZ8WPfpP0uSj6GJ9ICwoZsMDvFsyUdNHNScO9Ik1gLkrwTiMuvX1ouDifGZEOKmzAylxPsNuThnvBtp3EtjKBQgXvNMYm4Bd+P+KOwn7tRNpS2G9O5lWHe3nS8HIZmyC5omuBgndaUXUY52fTLY4oIosUNmBl7hKMqvZQxPTtpABd5OoWcfp5dWqRHqOAlcWKUMAa3VDM9O2kAF3k6hZx8ixKLFIwClhpBPOPwiVxjre4AGS/G5uILwNUpO7RtNQyF+mYQgesJ54+ztx8ilX2kiYMF9HZV+oknJbKFYl0TCErXUCo2sX0LOvXjCTvrHGIxXq9PFCvUWUKkY4ofMB6LE3AilvfqMjjEDoJi8gyK2yX4LrVGdbE2rYThhuC2vCIusBERJZRYQPWiRbWUzPpHlCrJd8WEZFcFTZgZWphRVXd1uRPEZFlVdiAFayJlSpgKelCRKTrChuwgi7BVEuMaPKniEjXFTZgrVwxzGh5OH3SheYdiYh0VWEDFvjjWI+lCVia/Cki0nWFnYcFGcszad6RiEhXFbqFZYyW041hTU3CNaeDvc7/f2oy92MTEZHFFLCatbCCwrfVg0DN///2ixW0RESWWa5dgmbFPQu4FhgGbvQcy4nY5xXAR4AycNhzrJfneUxhxmiZx6abTBxOKnyrLkIRkWWTWwvLrLjDwHXA2cCpwBvNintqwz7rgOuB13qOdRrw23kdT5R1q1O0sDQHS0SkJ+TZJXgmsN9zrIc9x5oBbgW2N+zzJuA2z7EeAfAc6wc5Hs8SxmiZp2fneXo2YeFBzcESEekJeXYJngyES5wfAl7SsM8LgLJZcf8VOAm41nOsTzb+IrPi7gB2AAwdTVn7LwVjtV/Q9vHpWVaVY5Z33/oa2HdT9HYREVk2eQasUsS2xoqxK4AzgG3AKHC3WXHv8Rzr2+GdPMfaBewCGL/zgx2rOmuEyjM9a+2q6J2+88Vs20VEJBd5BqxDQHjN9E3AoxH7HPYc6yhw1Ky4dwEvBL7NMlgXWhMrlsawRER6Qp4B615gq1lxtwDfBc7HH7MK+yfgY2bFXQGM4HcZXpPjMS2Sqp6gFm8UEekJuSVdeI51HLgIuAN4CJj0HOsBs+JeYFbcC+r7PAR8AZgCvoqf+v7NvI6pUbDESGILS3UERUR8tvE/sI0atrExtO392MZ+bONb2Mav5/n0uc7D8hzrc8DnGrbd0HD7z4A/y/M44hhplhgJ5lrtvdzvBjQ2+cFKc7BEpEhsYzPwauCR0LZT8XvPTgOeB9yJbbwAu5qQet26Qle6OGlVmVIJqkmrDk9NKliJiPjDNe9jcfLcduBW7Oox7OoBYD/+lKZcpGphmRX3POBK4Fn42X8loOY51tq8Dmw5DA+VOGnlivgW1p5LYd8nOPH3CcoygYKWiPSV975sZCO2sS+0aRd2dVeqB9vGa4HvYle/jm2E7zkZuCd0+1B9Wy7Sdgl+CDi3PuY0UIy4JUamJhcHq4DKMolIH/rw3TOHr/rKsfHYHWzjTuA5Efd8APgjIGryaZrpSx2TNmB9fxCDFcC60ZHoFtbey4l935XSLiKDxq6+Knq78fPAFiBoXW0CvoZtnEm66UsdkzZg7TMr7t8DnwWOBRs9x7otj4NaTrEV25OCklLaRaQo7Oo38IeD6rcNDxjHrh7GNnYDn8I2rsZPutiKn/Hd5Hcao8DzsavfynIoaZMu1gJP4TcJz63/OyfLE/UqY3XMmlixQamklHYREQC7+gAwCTyIP0XpwqYZgrZxLnB/fX+wjRfVA19TqVpYnmO9Nc1+/Si2hbVtp59gsWhpkRKMv03jVyJSXHbVbLh9BXBFlt+An0n4r/XH349tmPG7L0ibJbgJ+HPgl/AHdv4d+EPPsfp+MGfdqJ90UavVKJVC44eafyUikofj2NVqQ7ZhKmnHsP4K+BQL61X9bn3bqzM/Y48xRsvMzdc4OjPHM1Y2vB1jEwpQIiKd9U1s403AMLaxFbgY+EqaB6YNWM/0HOuvQrdvNivuJdmOsTedKM/01MzSgKVJwyIinfYH+Knyx/AbQncA/yvNA9MGrMNmxf1d4O/qt98I/CjjQfakcHmmTetDd0xNLh7D0qRhEZH22MYwsLueQv+BrA9PmyX4NmAC+C/ge8Bv1bf1PWPUX8RxSabg3ssbEi5YmDQsIiLZ+RmET2Eb2QewSJ8l+Ajw2laeoNfFFsDVOlgiInl4GvgGtvEl4OiJrXb14mYPTAxYZsX9cxLKbHiO1fQJep2xOiZgaR0sEZE8uPV/mTVrYe1rcn/fi111OGoeltbBEhFpj129BdsYAV5Q3/It7GrCGk8LEgOW51i3tHtsvW71yDArhkpLW1iahyUi0nm28QrgFsDDL567Gdt4M3b1rmYPbdYl+BHPsS4xK+7tRHQNeo7V9+NapVKJdavLPBZVnknzsEREOu3DwGtO1BG0jRfgZ6Cf0eyBzboE/7r+/1XtHF2vWzta5vGkVYdFRKRTyouK3trVb2Mb5TQPbNYleF/9/y8H28yKux7Y7DnWVGvH2nv88kwNqw5r0rCISB72YRs3sdAg+h3gvjQPTFtL8F/x09pX4FfZ/aFZcb/sOdalmQ+1BxmjZX745LGFDZo0LCKSl3cBF+KXZCoBdwHXp3lg2onDhudYjwPnAX/lOdYZQPRiX31o3eqRxWNYmjQsIpKXFcC12NXzsKuvBz4KDKd5YNqAtcKsuM/Fr3axp7Vj7F1LlhjRpGERkbzsBUZDt0eBO9M8MG3Auhy/QOF/eo51r1lxTwG+k+kQe5gxWuaJp48zN19PhIybHKxJwyIi7VqFXX3yxC3/59VpHpi2NNM/AP8Quv0w8JvZjrF3BeWZHp+eZf2aEU0aFhHJz1Fs4xewq18DwDbGgenkh/jSJl2cAlwLvBR/PtbdwCWeYx1o6XB7TLie4Po1I5o0LCKSn0uAf8A2HsWPJ88D3pDmgWmXF/kUcB3w+vrt84FbgZdkOswedWJNrPA4liYNi4h0jm28GDiIXb0X2/hZ4J34iXxfAFI1ftIGrJLnWH8duv03ZsW9KNPB9rDYiu0iItIpf8lCdvnLgD/CX8zxRcAu/GWrEqUNWP9iVtwKfquqht98c82KuwHAc6wjmQ67x4RXHT5BE4dFRDppGLsaxIo3ALuwq58GPo1t3J/mF6QNWEH/4jsbtr8NP4CdkvL39KS1oaQLQBOHRUQ6bxjbWIFdPQ5sA3aE7ksVi9JmCW5p4eD6RtAleGLycNLEYQUsEZFW/B3wZWzjMH5W4L8BYBs/DVTT/ILEeVhmxX1f6OffbrjvTzMebM9auWKY0fLwwhiWJg6LiHSWXb0CeC9wM/DL2NVgBZAh/LGsppq1sM4HPlT/+f2E5mIBZ+EPmg2EdavLnPK9z8E1E8QusqyJwyIirbOr90Rs+3bahzcLWKWYn6NuL2FW3LPw528NAzd6juXE7Pdi4B7gDZ5j/WOz35uH7UP/m9989GNQOxa9gyYOi4h0VbPSTLWYn6NuL2JW3GH8uVtnA6cCbzQr7qkx+12JX/qpa9799MdZGResRjfAuR/V+JWISBc1a2G90Ky4j+O3pkbrP1O/varJY88E9tfLOGFW3FuB7cCDDfv9AfBp4MVZDryjbnktJ9Uej7//eKqqISIikqNmCzimKvke42TgYOj2IRoqY5gV92T86hmvJCFgmRV3B/UUyKGjM3G7tWbPpXDgy8n9m8oQFBHpurTzsFoRFQMauxE/AlzmOdacWXFjf5HnWLvwZ0IzfucHE7siM7vv5nT7KUNQRKSr0i4v0opDwObQ7U3Aow37jAO3mhXXwy/Lcb1ZcV+X4zEtVZtLt58yBEVEuirPFta9wFaz4m4BvoufIv+m8A7hCclmxb0Z2OM51mdzPKalSsPpgpYyBEVEuiq3FpbnWMeBi/Cz/x4CJj3HesCsuBeYFfeCvJ43szPe0nyf8hqNX4mIdFmpVuvskFDexsfHa/v27evcL5yahNsvoTZ7ND7x4ryPK2CJSF8rlUr31Wq18W4fRzvy7BLsfaEit9HBqgTjb1OwEhGxjT/A7zU7DrjY1ffVt78feDswB1yMXc1tTm2eSRe9L6rIbcDYDOftgnOuXt5jEhHpNbbxa/jzaMewq6cBV9W3n4qfn3Aafrm+67GNdqZDJSp2Cys2Vb0E7/nmsh6KiEgPexfgYFf9ckB29Qf17duBW+vbD2Ab+/GLRtydx0EUO2AZm/y1rqK2i4gMkPe+bGQjthFOANiFXd2V8uEvAH4F27gCeBr4H9jVe/ELRIQL2h6qb8tFsQPWtp2LF2oEZkorGVEKu4gMmA/fPXP4qq8ci0+6sI07gedE3PMB/FixHngpflWiSWzjFNIViOiYYgesIJli7+VQPcR/lTbyxefs4PeVZCEiRWNXXxV/n/Eu4Lb6GlZfxTbmgY2kKxDRMcVOumgwVIKnZlJWvhARKY7P4td8Bdt4ATACHAZ2A+djGyuxjS3AVuCreR1EsVtYobR2gGfN/5C3/OgamPoppbKLiCz4BPAJbOObwAzw5npr6wFsYxJ/FY7jwIXY1dyu+os9cfia02OSLjYrS1BEBsogTBwudpdgVLACVWYXEelBxQ1YU5NEJ7hATWntIiI9p7gBa+/lRGVfztfg2Mv/5/Ifj4iIJCpuwEro9vvRKduX8UBERCSNYmQJTk2emGuFscmfMDy6HqaPLNn10dpGqk/NcPK60S4cqIiIxBn8FlaQul49CNT8/z/7bni6umTX+aEyHzo+QXV6dvmPU0REEg1+wIqqyD4/G7nK8Hx5Dbvnf5nqUwpYIiK9ZvADVoYU9eFjj/kPUQtLRKTnDH7AypKiXvKXcXlMAUtEpOcMfsDathPKKRMoanOsGCqphSUi0oMGP2CNTcC5H/XLLVHy/x/dELlrydjMutVlBSwRkR5UjLT2sYnFxWwbit4Cfits207WfqmspAsRkR40+C2sKFGtrnM/CmMTrBtVC0tEpBcVo4UVpbHVVWeMlvnhk8e6cEAiIpKkmC2sBOtWj6iFJSLSgxSwGhijZR7TGJaISM9RwGpgjJZ54unjzM3318KWIiKDrlhjWCeK4B70JwnX5vyEi207T4xnGaNlAB6fnmX9mpFuHq2IiIQUp4W1qAguC7UEqwf97VOTwELA0jiWiEhvKU7AiiqCG5idri/oCOtWK2CJiPSi4gSsZkVw6/cHLSzVExQR6S3FCVjNiuDW71cLS0SkN+WadGFW3LOAa4Fh4EbPsZyG+38HuKx+80ngXZ5jfT2Xg9m201+4cT4iEA2P+PcDa4MxrKdmcjkMERFpTW4tLLPiDgPXAWcDpwJvNCvuqQ27HQBe7jnWGPAnwK68joexCVh5UvR9I89YkiWoFpaISG/Js4V1JrDfc6yHAcyKeyuwHXgw2MFzrK+E9r8HyLB4VQumjzTdvnLFMKPlYU0eFhHpMXkGrJOBg6Hbh4CXJOz/duDzUXeYFXcHsANg6GgbXXXB3Kuo7SFaYkREpPfkGbBKEdsiy0eYFffX8APWL0fd7znWLurdheN3frD1EhRRwSpiuzFaVpagiEiPyTNL8BCwOXR7E/Bo405mxR0DbgS2e471oxyPp76cSPPthpYYERHpOXkGrHuBrWbF3WJW3BHgfGB3eAez4j4fuA34Pc+xvp3jsfi27fQXagyrL9wYZoyWeVwBS0Skp+QWsDzHOg5cBNwBPARMeo71gFlxLzAr7gX13XYCPwFcb1bc+82Kuy+v4wESF24MU8V2EZHeU6rV+qsq+fj4eG3fvnzj2hXug/zNPY/w0J+clevziIgsl1KpdF+tVhvv9nG0oziVLjIwRstMz85x7HhMkoaIiCw7BawIxmp/WRElXoiI9I5irYeV0rqgAO5TszzrpFVdPhoRkS6zjRcBNwCrgOPAu7GrX63f9378aUlzwMXY1TvyOgy1sCKsr7ewftzOJGURkcHxIeCPsasvwk+W+xAAtnEqfgb4acBZwPXYxnDM72ibAlaE9Wv8FtaPlSkoIgJ+0Ye19Z8NFubUbgduxa4ew64eAPbjl+XLhboEI2xYU29hqWK7iAyI975sZCO2EU6x3oVdTVtw/BLgDmzjKvyGzi/Wt5+MXwc2cKi+LRcKWBGCLsEj6hIUkQHx4btnDl/1lWPxae22cSfwnIh7PgBsA96DXf00tjEB3AS8igwl+DpBASvCqnJQsV0BS0QKwq6+Kv4+45PAH9Zv/QN+OT1IWYKvUzSGFWPDmhGOHNUYlogIfhB6ef3nVwLfqf+8Gzgf21iJbWwBtgJfzesg1MKKsW51WWNYIiK+dwDXYhsrgKepL/eEXX0A25jEX+fwOHAhdjW3igsKWDE2rBlRwBIRAbCr/w6cEXPfFcAVy3EY6hKMsX71iOZhiYj0EAWsGOtXl5UlKCLSQxSwYqxfM8LjTx/n+Nx8tw9FRERQwIoVTB5+TAVwRUR6ggJWjHX1ycOaiyUi0hsUsGJsOFHtQi0sEZFeoIAVIyiAq8QLEZHeoIAVY726BEVEeooCVowTBXAVsEREeoICVozREb8AriYPi4j0hmIFrKlJuOZ0sNf5/09NJu6+fnVZiziKiPSI4tQSnJqE2y+G2Wn/dvWgfxtgbCLyIevXqDyTiEivKE4La+/lC8EqMDvtb4+xYc2IxrBERHpEcQJW9VC27fiThx9Tl6CISE8oTsAyNmXbDmxQAVwRkZ5RnIC1bSeURxdvK4/622NsWLOS6vQssyqAKyLSdcUJWGMTcO5HwdgMlPz/z/1obMIFwE88IyjPpFaWiEi3FSdLEPzglBCgGm18xkoAfvjEMZ69dlVeRyUiIikUp4XVgmee5LewDj95rMtHIiIixQlYGScNw0IL6/CT6hIUEem2YnQJtjBpGBZ3CYqISHflGrDMinsWcC0wDNzoOZbTcH+pfv9vAE8Bb/Ec62sdP5CkScMJAWvNyhWMlofZddd/ctvX4udriYgshze8eDP//VdO6fZhdE1uAcusuMPAdcCrgUPAvWbF3e051oOh3c4Gttb/vQT4i/r/ndXCpOHAe169lfsPPtbZ4xERaUHQ61NUebawzgT2e471MIBZcW8FtgPhgLUd+KTnWDXgHrPirjMr7nM9x/peR4/E2OR3A0Ztb2LHr/5URw9FRERak2fAOhkIR4lDLG09Re1zMrAoYJkVdwewA2ColTlR23YuHsOCppOGRUSkt+QZsEoR22ot7IPnWLuAXQDjd35wyf1NBeNUey/3uwGNTX6wyjAnS0REuivPgHUI2By6vQl4tIV9OiPjpGEREekteQase4GtZsXdAnwXOB94U8M+u4GL6uNbLwGqHR+/EhGRgZDbxGHPsY4DFwF3AA8Bk55jPWBW3AvMintBfbfPAQ8D+4GPA+/O63hERKS/lWq17ENC3TQ+Pl7bt29ftw9DRKSvlEql+2q12ni3j6MdxSnNJCIifU0BS0RE+kLfdQmWSqUfAv+vlccOrV63cf6pxw53+JB6ml5zMeg1F0Obr/kna7XaMzt6QMutVqsV5t9PXrZnX7ePQa9Zr1mvWa9Zr7m1f+oSFBGRvqCAJSIifaFoAWtXtw+gC/Sai0GvuRiK+JpP6LukCxERKaaitbBERKRPKWCJiEhfyLP4bc8wK+5ZwLXAMHCj51hOlw+pI8yK+wngHOAHnmOdXt+2Afh7wAQ8YMJzrB/X73s/8HZgDrjYc6w7unDYbTEr7mbgk8BzgHlgl+dY1w7y6zYr7irgLmAl/nf2Hz3H+uAgv+ZAfeXyfcB3Pcc6Z9Bfs1lxPeAJ/Ndw3HOs8UF/zVkMfAur/oG/DjgbOBV4o1lxT+3uUXXMzcBZDdsqwF7PsbYCe+u3qb/m84HT6o+5vv7e9JvjwHs9x/o54KXAhfXXNsiv+xjwSs+xXgi8CDjLrLgvZbBfc+AP8YtnB4rwmn/Nc6wXeY4V1P0rwmtOZeADFnAmsN9zrIc9x5oBbgW2d/mYOsJzrLuAIw2btwO31H++BXhdaPutnmMd8xzrAH6F/DOX4zg7yXOs73mO9bX6z0/gn8xOZoBft+dYNc+xnqzfLNf/1Rjg1wxgVtxNgAXcGNo80K85RhFfc6QiBKyTgYOh24fq2wbVs4M1xer/P6u+feDeB7PimsB/A/4PA/66zYo7bFbc+4EfAF/yHGvgXzPwEeB9+F2/gUF/zTXgi2bFvc+suDvq2wb9NadWhIBVithWxFz+gXofzIr7DODTwCWeYz2esOtAvG7PseY8x3oR/qrcZ5oV9/SE3fv+NZsVNxibvS/lQ/r+Ndf9kudYv4A/hHGhWXF/NWHfQXnNqRUhYB0CNodubwIe7dKxLIfvmxX3uQD1/39Q3z4w74NZccv4wepvPce6rb554F83gOdYjwH/ij9mMciv+ZeA19aTEG4FXmlW3L9hsF8znmM9Wv//B8Bn8Lv4Bvo1Z1GEgHUvsNWsuFvMijuCP0i5u8vHlKfdwJvrP78Z+KfQ9vPNirvSrLhbgK3AV7twfG0xK24JuAl4yHOsq0N3DezrNivuM82Ku67+8yjwKuA/GODX7DnW+z3H2uQ5lon/nf1nz7F+lwF+zWbFXWNW3JOCn4HXAN9kgF9zVgMfsDzHOg5cBNyBP0A/6TnWA909qs4wK+7fAXcDP2NW3ENmxX074ACvNivud4BX129Tf82TwIPAF4ALPcea686Rt+WXgN/Dv+K+v/7vNxjs1/1c4F/MijuFfwH2Jc+x9jDYrznOIL/mZwP/blbcr+MHHtdzrC8w2K85E5VmEhGRvjDwLSwRERkMClgiItIXFLBERKQvKGCJiEhfUMASEZG+UIhq7SJZmRX32cA1+AV2fwzMAB/yHOszXT0wkQJTC0ukQX1y8meBuzzHOsVzrDPwJ69u6uqBiRSc5mGJNDAr7jZgp+dYL4+4zwT+GlhT33SR51hfMSvuK4A/Br6PvwTIbcA38JfHGAVe5znWf5oV95nADcDz64+/xHOs/53fqxEZHGphiSx1GvC1mPt+ALy6XqD0DcBHQ/e9ED9A/Tx+NY4XeI51Jv7yGH9Q3+da4BrPsV4M/CaLl84QkQQawxJpwqy41wG/jD+O9SrgY2bFfRH+Kq8vCO16b7AMhFlx/xP4Yn37N4Bfq//8KuBUs+IGj1lrVtyT6mt7iUgCBSyRpR7Ab/0A4DnWhWbF3Yi/VPt78Lv9XojfQ/F06HHHQj/Ph27Ps/BdGwJe5jnWdD6HLjK41CUostQ/A6vMivuu0LbV9f8N4HueY83jd/tlXZL8i/jFmAGot9REJAW1sEQaeI5VMyvu64BrzIr7PuCHwFHgMvyxrU+bFfe3gX+pb8/iYuC6euX1FcBdwAWdOnaRQaYsQRER6QvqEhQRkb6ggCUiIn1BAUtERPqCApaIiPQFBSwREekLClgiItIXFLBERKQv/H+UZJrzTXwlOAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import gym\n",
    "#from simple_dqn_torch_2020 import Agent\n",
    "#from utils import plotLearning\n",
    "import numpy as np\n",
    "\n",
    "#t=[[0,5,4],[0,4,4],[0,3,4],[0,3,4],[0,3,4],[1,7,4],[1,8,4],[0,3,4],[0,8,4]]\n",
    "if __name__ == '__main__':\n",
    "    #env = gym.make('CartPole-v1')\n",
    "    env=CartPoleEnv3()\n",
    "    agent = Agent(gamma=0.99, epsilon=1.0, batch_size=64, n_actions=2, eps_end=0.01,\n",
    "                  input_dims=[4], lr=0.001)\n",
    "    scores, eps_history = [], []\n",
    "    n_games =500\n",
    "    x_dot=20\n",
    "    #dot=[[1,20],[1,21],[1,22],[1,24],[1,25],[1,20],[1,21],[1,22],[1,24],[1,25],[1,20],[1,21],[1,22],[1,24],[1,25],[1,20],[1,21],[1,22],[1,24],[1,25]]\n",
    "    \n",
    "    for i in range(n_games):\n",
    "        score = 0\n",
    "        done = False\n",
    "        observation = env.reset()\n",
    "        #observation=env.step(action)\n",
    "        \n",
    "        while not done:\n",
    "            \n",
    "            action = agent.choose_action(observation)\n",
    "            observation_, reward, done, info = env.step(action)\n",
    "            score += reward\n",
    "            agent.store_transition(observation, action, reward, \n",
    "                                    observation_, done)\n",
    "            agent.learn()\n",
    "            observation = observation_\n",
    "        scores.append(score)\n",
    "        eps_history.append(agent.epsilon)\n",
    "        \n",
    "        avg_score = np.mean(scores[-100:])\n",
    "\n",
    "        print('episode ', i, 'score %.2f' % score,\n",
    "                'average score %.2f' % avg_score,\n",
    "                'epsilon %.2f' % agent.epsilon)\n",
    "    x = [i+1 for i in range(n_games)]\n",
    "    #filename = 'lunar_lander.png'\n",
    "    plotLearning(x, scores, eps_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "t=[[1,5,4],[1,4,4],[1,3,4],[1,3,4],[1,3,4],[1,7,4],[1,8,4],[1,3,4],[1,8,4]]\n",
    "for i in range(len(t)):\n",
    "  r=random.choices(t)\n",
    "  if random.random()<.5:\n",
    "        if r[0][0]==1 and random.random()<math.exp(-1):\n",
    "          print(r[0][1])\n",
    "  else:\n",
    "    print('wrong')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r=math.exp(-1)\n",
    "print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=[[1,5,4],[1,4,4],[1,3,4],[1,3,4],[1,3,4],[1,7,4],[1,8,4],[1,3,4],[1,8,4]]\n",
    "for i in range(len(t)):\n",
    "    x=t[i][0]+5\n",
    "    t[i][0]=x\n",
    "    print(t[i][0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=[[1,5,4],[1,4,4],[1,3,4],[1,3,4],[1,3,4],[0,7,4],[1,8,4],[1,3,4],[1,8,4]]\n",
    "\n",
    "a=0\n",
    "for i in range(len(t)):\n",
    "  if t[i][0]==1:\n",
    "     a-=1\n",
    "    \n",
    "    \n",
    "print(a)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " a=0\n",
    "         for i in range(len(t)):\n",
    "           if t[i][0]==1:\n",
    "              a+=1\n",
    "         b=9-a\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.zeros((5,3), dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[3]*[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%history -g -f MDP_IOT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%history -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = np_random.uniform(low=0, high=1, size=(4,))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    " print(random.random())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
